{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어처리 + 분류\n",
    "### 자연어 기반 기후기술분류 AI 경진대회 데이터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score,f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/open/'\n",
    "\n",
    "train=pd.read_csv(data_path + 'train.csv')\n",
    "test=pd.read_csv(data_path +'test.csv')\n",
    "sample_submission=pd.read_csv(data_path +'sample_submission.csv')\n",
    "\n",
    "train = train[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>제출년도</th>\n",
       "      <th>사업명</th>\n",
       "      <th>사업_부처명</th>\n",
       "      <th>계속과제여부</th>\n",
       "      <th>내역사업명</th>\n",
       "      <th>과제명</th>\n",
       "      <th>요약문_연구목표</th>\n",
       "      <th>요약문_연구내용</th>\n",
       "      <th>요약문_기대효과</th>\n",
       "      <th>요약문_한글키워드</th>\n",
       "      <th>요약문_영문키워드</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>농업기초기반연구</td>\n",
       "      <td>농촌진흥청</td>\n",
       "      <td>신규</td>\n",
       "      <td>농산물안전성연구</td>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발</td>\n",
       "      <td>○ 새로운 해충분류군의 동정기술 개발 및 유입확산 추적</td>\n",
       "      <td>(가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...</td>\n",
       "      <td>○ 새로운 돌발 및 외래해충의 신속, 정확한 동정법 향상\\n\\n\\n○ 돌발 및 외래...</td>\n",
       "      <td>뉴클레오티드 염기서열, 분자마커, 종 동정, 침샘, 전사체</td>\n",
       "      <td>nucleotide sequence, molecular marker, species...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>이공학학술연구기반구축(R&amp;D)</td>\n",
       "      <td>교육부</td>\n",
       "      <td>신규</td>\n",
       "      <td>지역대학우수과학자지원사업(1년~5년)</td>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "      <td>최종목표:  TRAIL 감수성 표적 유전자를 발굴하고 내성제어 기전을 연구. 발굴된...</td>\n",
       "      <td>1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...</td>\n",
       "      <td>1) TRAIL 내성 특이적 표적분자를 발굴하고, 이를 이용한 TRAIL 효과 증진...</td>\n",
       "      <td>대장암,항암제 내성,세포사멸,유전자발굴</td>\n",
       "      <td>TRAIL,Colorectal cancer,TRAIL resistance,Apopt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016</td>\n",
       "      <td>중소기업기술혁신개발</td>\n",
       "      <td>중소기업청</td>\n",
       "      <td>신규</td>\n",
       "      <td>혁신기업기술개발</td>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "      <td>* 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n* 소비자 및 바...</td>\n",
       "      <td>* 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...</td>\n",
       "      <td>* 국내 독자적인 비목질계 셀룰로오스 자원의 파이버 및 부직포 제조 등의 기술 확보...</td>\n",
       "      <td>기능성 샐룰로오스 파이버,천연섬유,기능성 부직포,뷰티&amp;amp;케어 제품,미용 솜</td>\n",
       "      <td>functional cellulose fiber,natural fiber,funct...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>창업성장기술개발(R&amp;D)</td>\n",
       "      <td>중소벤처기업부</td>\n",
       "      <td>신규</td>\n",
       "      <td>창업사업화연계과제</td>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발</td>\n",
       "      <td>#  암특이적 바이오마커 발굴 및 바이오마커에 대한 프로브 개발\\n\\n\\n1) 소화...</td>\n",
       "      <td># 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...</td>\n",
       "      <td># 암 진단기술의 차별성: 소화기 암 특이 프로브 개발\\n\\n\\n- 최근 체외진단시...</td>\n",
       "      <td>분자 진단,형광 조영제,프로브,항체,대장암</td>\n",
       "      <td>Molecular diagnosis,Fluorescence,probe,antibod...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016</td>\n",
       "      <td>이공학개인기초연구지원</td>\n",
       "      <td>교육부</td>\n",
       "      <td>계속</td>\n",
       "      <td>기본연구지원</td>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사</td>\n",
       "      <td>수술이 불가능한 위암환자는 생존기간은 10개월 안팎에 지나지 않고, 항암화학요법에 ...</td>\n",
       "      <td>-In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...</td>\n",
       "      <td>-본 연구는 파라핀보관조직에서 in situ hybridization로 mRNA 및...</td>\n",
       "      <td>BRCA,제자리부합법,조직미세배열,마이크로RNA,위암,항암제반응,젊은 연령/가족성 위암</td>\n",
       "      <td>BRCA,Insituhybridization,tissuemicroarray,micr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>2017</td>\n",
       "      <td>개인기초연구(교육부)</td>\n",
       "      <td>교육부</td>\n",
       "      <td>신규</td>\n",
       "      <td>지역대학우수과학자지원사업</td>\n",
       "      <td>곤충유래 항생단백질 발굴 및 세포성면역 연구</td>\n",
       "      <td>본 연구는 한국 토착 곤충들을 대상으로 유용유전자(항생단백질)의 발굴 및 활용 가능...</td>\n",
       "      <td>곤충은 지구상에 약 80만종이 알려져 있고 동물 중 80%를 차지하는 최대의 미개발...</td>\n",
       "      <td>1. 다양한 미생물에 노출되어 살아가는(면역체계가 잘 발달되었으리라 판단) 곤충을 ...</td>\n",
       "      <td>곤충, 미생물, 채액성면역, 세포성면역, 항생단백질, 혈구세포</td>\n",
       "      <td>Insects,Microorganisms,Humoralimmuneresponse,C...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>2017</td>\n",
       "      <td>토양지하수오염방지기술개발</td>\n",
       "      <td>환경부</td>\n",
       "      <td>계속</td>\n",
       "      <td>오염조사기술</td>\n",
       "      <td>토양 및 지하수의 물리화학적 특성에 기반한 제조나노물질의 환경거동 및 위해성 평가기...</td>\n",
       "      <td>토양·지하수의 물리화학적 특성에 기반 한 제조나노물질의 위해성 영향평가 기술 개발(...</td>\n",
       "      <td>Attachment efficiency에 의한 토양 내의 탄소기반 나노입자의 거동 ...</td>\n",
       "      <td>국내 매립지, 토양복원/지하수 개발사업 대상이며, 그 중 제조나노물질의 사회적 영향...</td>\n",
       "      <td>제조나노물질, 생태위해성, 토양환경, 토양유기물 난분해성유기물질</td>\n",
       "      <td>manufactured nanomaterials, ecotoxicology, soi...</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>2017</td>\n",
       "      <td>방송통신산업기술개발</td>\n",
       "      <td>과학기술정보통신부</td>\n",
       "      <td>신규</td>\n",
       "      <td>보안과제정보</td>\n",
       "      <td>보안과제정보</td>\n",
       "      <td>보안과제정보</td>\n",
       "      <td>보안과제정보</td>\n",
       "      <td>보안과제정보</td>\n",
       "      <td>보안과제정보</td>\n",
       "      <td>보안과제정보</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>2016</td>\n",
       "      <td>글로벌연구네트워크지원</td>\n",
       "      <td>교육부</td>\n",
       "      <td>신규</td>\n",
       "      <td>글로벌연구네트워크지원사업</td>\n",
       "      <td>혁신적 콘텐츠 산업 발전을 위한 CT(Culture technology) 협력: 국...</td>\n",
       "      <td>？ 제안된 연구는 혁신적 콘텐츠 산업 발전을 위한 문화 기술협력에 대한 연구로, 특...</td>\n",
       "      <td>？ 이론적으로, 본 연구는 주로 한국에서 논의되어 왔던 CT 를 글로벌 관점으로 확...</td>\n",
       "      <td>？ 글로벌 관점에서 문화기술 정의 \\n\\n\\n-본 연구에서는 글로벌 관점에서 문화산...</td>\n",
       "      <td>혁신적 콘텐츠 산업 발전을 위한 CT(Culture technology) 협력: 국...</td>\n",
       "      <td>Culture technology, Technology cooperation, Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>2018</td>\n",
       "      <td>뇌과학원천기술개발(R&amp;D)</td>\n",
       "      <td>과학기술정보통신부</td>\n",
       "      <td>계속</td>\n",
       "      <td>뇌과학원천기술개발사업</td>\n",
       "      <td>자연지능 및 뇌질환의 수학적 모델에 대한 동특성 해석에 관한 연구</td>\n",
       "      <td>본 과제의 목표는 자연지능 및 뇌질환의 수학적 모델에 대한 동특성 해석에 관한 연구...</td>\n",
       "      <td>본 연구개발의 주요 목적은 자연지능의 여러 가지 특성을 고려한 수학적 모델링을 구성...</td>\n",
       "      <td>· 자연지능 및 뇌질환 연구를 수학적 모델을 통해 여러 가지 현상에 분석 기대\\n\\...</td>\n",
       "      <td>자연지능,안정성,강인성,뇌질환,치료 및 조절</td>\n",
       "      <td>Natural intelligence,Stability,Robustness,Brai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  제출년도               사업명     사업_부처명 계속과제여부                 내역사업명  \\\n",
       "0         0  2016          농업기초기반연구      농촌진흥청     신규              농산물안전성연구   \n",
       "1         1  2019  이공학학술연구기반구축(R&D)        교육부     신규  지역대학우수과학자지원사업(1년~5년)   \n",
       "2         2  2016        중소기업기술혁신개발      중소기업청     신규              혁신기업기술개발   \n",
       "3         3  2018     창업성장기술개발(R&D)    중소벤처기업부     신규             창업사업화연계과제   \n",
       "4         4  2016       이공학개인기초연구지원        교육부     계속                기본연구지원   \n",
       "...     ...   ...               ...        ...    ...                   ...   \n",
       "9995   9995  2017       개인기초연구(교육부)        교육부     신규         지역대학우수과학자지원사업   \n",
       "9996   9996  2017     토양지하수오염방지기술개발        환경부     계속                오염조사기술   \n",
       "9997   9997  2017        방송통신산업기술개발  과학기술정보통신부     신규                보안과제정보   \n",
       "9998   9998  2016       글로벌연구네트워크지원        교육부     신규         글로벌연구네트워크지원사업   \n",
       "9999   9999  2018    뇌과학원천기술개발(R&D)  과학기술정보통신부     계속           뇌과학원천기술개발사업   \n",
       "\n",
       "                                                    과제명  \\\n",
       "0                          유전정보를 활용한 새로운 해충 분류군 동정기술 개발   \n",
       "1     대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...   \n",
       "2     비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...   \n",
       "3                               소화기 암 진단용 분자영상 형광프로브 개발   \n",
       "4                           위암환자의 항암제반응예측을 위한 BRCA 발현검사   \n",
       "...                                                 ...   \n",
       "9995                           곤충유래 항생단백질 발굴 및 세포성면역 연구   \n",
       "9996  토양 및 지하수의 물리화학적 특성에 기반한 제조나노물질의 환경거동 및 위해성 평가기...   \n",
       "9997                                             보안과제정보   \n",
       "9998  혁신적 콘텐츠 산업 발전을 위한 CT(Culture technology) 협력: 국...   \n",
       "9999               자연지능 및 뇌질환의 수학적 모델에 대한 동특성 해석에 관한 연구   \n",
       "\n",
       "                                               요약문_연구목표  \\\n",
       "0                        ○ 새로운 해충분류군의 동정기술 개발 및 유입확산 추적   \n",
       "1     최종목표:  TRAIL 감수성 표적 유전자를 발굴하고 내성제어 기전을 연구. 발굴된...   \n",
       "2     * 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n* 소비자 및 바...   \n",
       "3     #  암특이적 바이오마커 발굴 및 바이오마커에 대한 프로브 개발\\n\\n\\n1) 소화...   \n",
       "4     수술이 불가능한 위암환자는 생존기간은 10개월 안팎에 지나지 않고, 항암화학요법에 ...   \n",
       "...                                                 ...   \n",
       "9995  본 연구는 한국 토착 곤충들을 대상으로 유용유전자(항생단백질)의 발굴 및 활용 가능...   \n",
       "9996  토양·지하수의 물리화학적 특성에 기반 한 제조나노물질의 위해성 영향평가 기술 개발(...   \n",
       "9997                                             보안과제정보   \n",
       "9998  ？ 제안된 연구는 혁신적 콘텐츠 산업 발전을 위한 문화 기술협력에 대한 연구로, 특...   \n",
       "9999  본 과제의 목표는 자연지능 및 뇌질환의 수학적 모델에 대한 동특성 해석에 관한 연구...   \n",
       "\n",
       "                                               요약문_연구내용  \\\n",
       "0     (가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...   \n",
       "1     1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...   \n",
       "2     * 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...   \n",
       "3     # 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...   \n",
       "4     -In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...   \n",
       "...                                                 ...   \n",
       "9995  곤충은 지구상에 약 80만종이 알려져 있고 동물 중 80%를 차지하는 최대의 미개발...   \n",
       "9996  Attachment efficiency에 의한 토양 내의 탄소기반 나노입자의 거동 ...   \n",
       "9997                                             보안과제정보   \n",
       "9998  ？ 이론적으로, 본 연구는 주로 한국에서 논의되어 왔던 CT 를 글로벌 관점으로 확...   \n",
       "9999  본 연구개발의 주요 목적은 자연지능의 여러 가지 특성을 고려한 수학적 모델링을 구성...   \n",
       "\n",
       "                                               요약문_기대효과  \\\n",
       "0     ○ 새로운 돌발 및 외래해충의 신속, 정확한 동정법 향상\\n\\n\\n○ 돌발 및 외래...   \n",
       "1     1) TRAIL 내성 특이적 표적분자를 발굴하고, 이를 이용한 TRAIL 효과 증진...   \n",
       "2     * 국내 독자적인 비목질계 셀룰로오스 자원의 파이버 및 부직포 제조 등의 기술 확보...   \n",
       "3     # 암 진단기술의 차별성: 소화기 암 특이 프로브 개발\\n\\n\\n- 최근 체외진단시...   \n",
       "4     -본 연구는 파라핀보관조직에서 in situ hybridization로 mRNA 및...   \n",
       "...                                                 ...   \n",
       "9995  1. 다양한 미생물에 노출되어 살아가는(면역체계가 잘 발달되었으리라 판단) 곤충을 ...   \n",
       "9996  국내 매립지, 토양복원/지하수 개발사업 대상이며, 그 중 제조나노물질의 사회적 영향...   \n",
       "9997                                             보안과제정보   \n",
       "9998  ？ 글로벌 관점에서 문화기술 정의 \\n\\n\\n-본 연구에서는 글로벌 관점에서 문화산...   \n",
       "9999  · 자연지능 및 뇌질환 연구를 수학적 모델을 통해 여러 가지 현상에 분석 기대\\n\\...   \n",
       "\n",
       "                                              요약문_한글키워드  \\\n",
       "0                      뉴클레오티드 염기서열, 분자마커, 종 동정, 침샘, 전사체   \n",
       "1                                 대장암,항암제 내성,세포사멸,유전자발굴   \n",
       "2          기능성 샐룰로오스 파이버,천연섬유,기능성 부직포,뷰티&amp;케어 제품,미용 솜   \n",
       "3                               분자 진단,형광 조영제,프로브,항체,대장암   \n",
       "4      BRCA,제자리부합법,조직미세배열,마이크로RNA,위암,항암제반응,젊은 연령/가족성 위암   \n",
       "...                                                 ...   \n",
       "9995                 곤충, 미생물, 채액성면역, 세포성면역, 항생단백질, 혈구세포   \n",
       "9996                제조나노물질, 생태위해성, 토양환경, 토양유기물 난분해성유기물질   \n",
       "9997                                             보안과제정보   \n",
       "9998  혁신적 콘텐츠 산업 발전을 위한 CT(Culture technology) 협력: 국...   \n",
       "9999                           자연지능,안정성,강인성,뇌질환,치료 및 조절   \n",
       "\n",
       "                                              요약문_영문키워드  label  \n",
       "0     nucleotide sequence, molecular marker, species...     24  \n",
       "1     TRAIL,Colorectal cancer,TRAIL resistance,Apopt...      0  \n",
       "2     functional cellulose fiber,natural fiber,funct...      0  \n",
       "3     Molecular diagnosis,Fluorescence,probe,antibod...      0  \n",
       "4     BRCA,Insituhybridization,tissuemicroarray,micr...      0  \n",
       "...                                                 ...    ...  \n",
       "9995  Insects,Microorganisms,Humoralimmuneresponse,C...      0  \n",
       "9996  manufactured nanomaterials, ecotoxicology, soi...     27  \n",
       "9997                                             보안과제정보      0  \n",
       "9998  Culture technology, Technology cooperation, Co...      0  \n",
       "9999  Natural intelligence,Stability,Robustness,Brai...      0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\core\\series.py:4439: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "train=train[['과제명', '요약문_연구내용','label']]\n",
    "test=test[['과제명', '요약문_연구내용']]\n",
    "\n",
    "train['요약문_연구내용'].fillna('NAN', inplace=True)\n",
    "test['요약문_연구내용'].fillna('NAN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train['data']=train['과제명']+train['요약문_연구내용']\n",
    "test['data']=test['과제명']+test['요약문_연구내용']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과제명</th>\n",
       "      <th>요약문_연구내용</th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발</td>\n",
       "      <td>(가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...</td>\n",
       "      <td>24</td>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "      <td>1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...</td>\n",
       "      <td>0</td>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "      <td>* 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...</td>\n",
       "      <td>0</td>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발</td>\n",
       "      <td># 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발# 소화기 암 진단용 분자영상 형광프로브 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사</td>\n",
       "      <td>-In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사-In situ hybridizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>곤충유래 항생단백질 발굴 및 세포성면역 연구</td>\n",
       "      <td>곤충은 지구상에 약 80만종이 알려져 있고 동물 중 80%를 차지하는 최대의 미개발...</td>\n",
       "      <td>0</td>\n",
       "      <td>곤충유래 항생단백질 발굴 및 세포성면역 연구곤충은 지구상에 약 80만종이 알려져 있...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>토양 및 지하수의 물리화학적 특성에 기반한 제조나노물질의 환경거동 및 위해성 평가기...</td>\n",
       "      <td>Attachment efficiency에 의한 토양 내의 탄소기반 나노입자의 거동 ...</td>\n",
       "      <td>27</td>\n",
       "      <td>토양 및 지하수의 물리화학적 특성에 기반한 제조나노물질의 환경거동 및 위해성 평가기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>보안과제정보</td>\n",
       "      <td>보안과제정보</td>\n",
       "      <td>0</td>\n",
       "      <td>보안과제정보보안과제정보</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>혁신적 콘텐츠 산업 발전을 위한 CT(Culture technology) 협력: 국...</td>\n",
       "      <td>？ 이론적으로, 본 연구는 주로 한국에서 논의되어 왔던 CT 를 글로벌 관점으로 확...</td>\n",
       "      <td>0</td>\n",
       "      <td>혁신적 콘텐츠 산업 발전을 위한 CT(Culture technology) 협력: 국...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>자연지능 및 뇌질환의 수학적 모델에 대한 동특성 해석에 관한 연구</td>\n",
       "      <td>본 연구개발의 주요 목적은 자연지능의 여러 가지 특성을 고려한 수학적 모델링을 구성...</td>\n",
       "      <td>0</td>\n",
       "      <td>자연지능 및 뇌질환의 수학적 모델에 대한 동특성 해석에 관한 연구본 연구개발의 주요...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    과제명  \\\n",
       "0                          유전정보를 활용한 새로운 해충 분류군 동정기술 개발   \n",
       "1     대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...   \n",
       "2     비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...   \n",
       "3                               소화기 암 진단용 분자영상 형광프로브 개발   \n",
       "4                           위암환자의 항암제반응예측을 위한 BRCA 발현검사   \n",
       "...                                                 ...   \n",
       "9995                           곤충유래 항생단백질 발굴 및 세포성면역 연구   \n",
       "9996  토양 및 지하수의 물리화학적 특성에 기반한 제조나노물질의 환경거동 및 위해성 평가기...   \n",
       "9997                                             보안과제정보   \n",
       "9998  혁신적 콘텐츠 산업 발전을 위한 CT(Culture technology) 협력: 국...   \n",
       "9999               자연지능 및 뇌질환의 수학적 모델에 대한 동특성 해석에 관한 연구   \n",
       "\n",
       "                                               요약문_연구내용  label  \\\n",
       "0     (가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...     24   \n",
       "1     1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...      0   \n",
       "2     * 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...      0   \n",
       "3     # 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...      0   \n",
       "4     -In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...      0   \n",
       "...                                                 ...    ...   \n",
       "9995  곤충은 지구상에 약 80만종이 알려져 있고 동물 중 80%를 차지하는 최대의 미개발...      0   \n",
       "9996  Attachment efficiency에 의한 토양 내의 탄소기반 나노입자의 거동 ...     27   \n",
       "9997                                             보안과제정보      0   \n",
       "9998  ？ 이론적으로, 본 연구는 주로 한국에서 논의되어 왔던 CT 를 글로벌 관점으로 확...      0   \n",
       "9999  본 연구개발의 주요 목적은 자연지능의 여러 가지 특성을 고려한 수학적 모델링을 구성...      0   \n",
       "\n",
       "                                                   data  \n",
       "0     유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...  \n",
       "1     대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...  \n",
       "2     비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...  \n",
       "3     소화기 암 진단용 분자영상 형광프로브 개발# 소화기 암 진단용 분자영상 형광프로브 ...  \n",
       "4     위암환자의 항암제반응예측을 위한 BRCA 발현검사-In situ hybridizat...  \n",
       "...                                                 ...  \n",
       "9995  곤충유래 항생단백질 발굴 및 세포성면역 연구곤충은 지구상에 약 80만종이 알려져 있...  \n",
       "9996  토양 및 지하수의 물리화학적 특성에 기반한 제조나노물질의 환경거동 및 위해성 평가기...  \n",
       "9997                                       보안과제정보보안과제정보  \n",
       "9998  혁신적 콘텐츠 산업 발전을 위한 CT(Culture technology) 협력: 국...  \n",
       "9999  자연지능 및 뇌질환의 수학적 모델에 대한 동특성 해석에 관한 연구본 연구개발의 주요...  \n",
       "\n",
       "[10000 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "def text_preprocess(x):\n",
    "    text=[]\n",
    "    a = re.sub('[^가-힣0-9a-zA-Z\\\\s]', '',x)\n",
    "    for j in a.split():\n",
    "        text.append(j)\n",
    "    return ' '.join(text)\n",
    "\n",
    "def tokenize(x):\n",
    "    text = []\n",
    "    tokens = okt.pos(x)\n",
    "    for token in tokens :\n",
    "        if token[1] == 'Adjective' or token[1]=='Adverb' or token[1] == 'Determiner' or token[1] == 'Noun' or token[1] == 'Verb' or 'Unknown':\n",
    "            text.append(token[0])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 10000/10000 [05:37<00:00, 29.64it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과제명</th>\n",
       "      <th>요약문_연구내용</th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발</td>\n",
       "      <td>(가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...</td>\n",
       "      <td>24</td>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...</td>\n",
       "      <td>[유전, 정보, 를, 활용, 한, 새로운, 해충, 분류군, 동정, 기술, 개발, 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "      <td>1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...</td>\n",
       "      <td>0</td>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "      <td>[대장암, 의, TRAIL, 내, 성, 표적, 인자, 발굴, 및, TRAIL, 반응...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "      <td>* 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...</td>\n",
       "      <td>0</td>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "      <td>[비목, 질계, 셀룰로오스, 식물, 자원, 을, 활용, 한, 기능, 성, 부직포, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발</td>\n",
       "      <td># 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발# 소화기 암 진단용 분자영상 형광프로브 ...</td>\n",
       "      <td>[소화기, 암, 진단, 용, 분자영상, 형광, 프로, 브, 개발, 소화기, 암, 진...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사</td>\n",
       "      <td>-In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사-In situ hybridizat...</td>\n",
       "      <td>[위암, 환자, 의, 항암제, 반응, 예측, 을, 위, 한, BRCA, 발현, 검사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>곤충유래 항생단백질 발굴 및 세포성면역 연구</td>\n",
       "      <td>곤충은 지구상에 약 80만종이 알려져 있고 동물 중 80%를 차지하는 최대의 미개발...</td>\n",
       "      <td>0</td>\n",
       "      <td>곤충유래 항생단백질 발굴 및 세포성면역 연구곤충은 지구상에 약 80만종이 알려져 있...</td>\n",
       "      <td>[곤충, 유래, 항생, 단백질, 발굴, 및, 세포, 성, 면역, 연, 구, 곤충, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>토양 및 지하수의 물리화학적 특성에 기반한 제조나노물질의 환경거동 및 위해성 평가기...</td>\n",
       "      <td>Attachment efficiency에 의한 토양 내의 탄소기반 나노입자의 거동 ...</td>\n",
       "      <td>27</td>\n",
       "      <td>토양 및 지하수의 물리화학적 특성에 기반한 제조나노물질의 환경거동 및 위해성 평가기...</td>\n",
       "      <td>[토양, 및, 지하수, 의, 물리화학, 적, 특성, 에, 기반, 한, 제, 조, 나...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>보안과제정보</td>\n",
       "      <td>보안과제정보</td>\n",
       "      <td>0</td>\n",
       "      <td>보안과제정보보안과제정보</td>\n",
       "      <td>[보안, 과, 제, 정보보안, 과, 제, 정보]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>혁신적 콘텐츠 산업 발전을 위한 CT(Culture technology) 협력: 국...</td>\n",
       "      <td>？ 이론적으로, 본 연구는 주로 한국에서 논의되어 왔던 CT 를 글로벌 관점으로 확...</td>\n",
       "      <td>0</td>\n",
       "      <td>혁신적 콘텐츠 산업 발전을 위한 CT(Culture technology) 협력: 국...</td>\n",
       "      <td>[혁신, 적, 콘텐츠, 산업, 발전, 을, 위, 한, CTCulture, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>자연지능 및 뇌질환의 수학적 모델에 대한 동특성 해석에 관한 연구</td>\n",
       "      <td>본 연구개발의 주요 목적은 자연지능의 여러 가지 특성을 고려한 수학적 모델링을 구성...</td>\n",
       "      <td>0</td>\n",
       "      <td>자연지능 및 뇌질환의 수학적 모델에 대한 동특성 해석에 관한 연구본 연구개발의 주요...</td>\n",
       "      <td>[자연, 지능, 및, 뇌, 질환, 의, 수학, 적, 모델, 에, 대한, 동, 특성,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    과제명  \\\n",
       "0                          유전정보를 활용한 새로운 해충 분류군 동정기술 개발   \n",
       "1     대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...   \n",
       "2     비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...   \n",
       "3                               소화기 암 진단용 분자영상 형광프로브 개발   \n",
       "4                           위암환자의 항암제반응예측을 위한 BRCA 발현검사   \n",
       "...                                                 ...   \n",
       "9995                           곤충유래 항생단백질 발굴 및 세포성면역 연구   \n",
       "9996  토양 및 지하수의 물리화학적 특성에 기반한 제조나노물질의 환경거동 및 위해성 평가기...   \n",
       "9997                                             보안과제정보   \n",
       "9998  혁신적 콘텐츠 산업 발전을 위한 CT(Culture technology) 협력: 국...   \n",
       "9999               자연지능 및 뇌질환의 수학적 모델에 대한 동특성 해석에 관한 연구   \n",
       "\n",
       "                                               요약문_연구내용  label  \\\n",
       "0     (가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...     24   \n",
       "1     1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...      0   \n",
       "2     * 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...      0   \n",
       "3     # 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...      0   \n",
       "4     -In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...      0   \n",
       "...                                                 ...    ...   \n",
       "9995  곤충은 지구상에 약 80만종이 알려져 있고 동물 중 80%를 차지하는 최대의 미개발...      0   \n",
       "9996  Attachment efficiency에 의한 토양 내의 탄소기반 나노입자의 거동 ...     27   \n",
       "9997                                             보안과제정보      0   \n",
       "9998  ？ 이론적으로, 본 연구는 주로 한국에서 논의되어 왔던 CT 를 글로벌 관점으로 확...      0   \n",
       "9999  본 연구개발의 주요 목적은 자연지능의 여러 가지 특성을 고려한 수학적 모델링을 구성...      0   \n",
       "\n",
       "                                                   data  \\\n",
       "0     유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...   \n",
       "1     대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...   \n",
       "2     비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...   \n",
       "3     소화기 암 진단용 분자영상 형광프로브 개발# 소화기 암 진단용 분자영상 형광프로브 ...   \n",
       "4     위암환자의 항암제반응예측을 위한 BRCA 발현검사-In situ hybridizat...   \n",
       "...                                                 ...   \n",
       "9995  곤충유래 항생단백질 발굴 및 세포성면역 연구곤충은 지구상에 약 80만종이 알려져 있...   \n",
       "9996  토양 및 지하수의 물리화학적 특성에 기반한 제조나노물질의 환경거동 및 위해성 평가기...   \n",
       "9997                                       보안과제정보보안과제정보   \n",
       "9998  혁신적 콘텐츠 산업 발전을 위한 CT(Culture technology) 협력: 국...   \n",
       "9999  자연지능 및 뇌질환의 수학적 모델에 대한 동특성 해석에 관한 연구본 연구개발의 주요...   \n",
       "\n",
       "                                               contents  \n",
       "0     [유전, 정보, 를, 활용, 한, 새로운, 해충, 분류군, 동정, 기술, 개발, 가...  \n",
       "1     [대장암, 의, TRAIL, 내, 성, 표적, 인자, 발굴, 및, TRAIL, 반응...  \n",
       "2     [비목, 질계, 셀룰로오스, 식물, 자원, 을, 활용, 한, 기능, 성, 부직포, ...  \n",
       "3     [소화기, 암, 진단, 용, 분자영상, 형광, 프로, 브, 개발, 소화기, 암, 진...  \n",
       "4     [위암, 환자, 의, 항암제, 반응, 예측, 을, 위, 한, BRCA, 발현, 검사...  \n",
       "...                                                 ...  \n",
       "9995  [곤충, 유래, 항생, 단백질, 발굴, 및, 세포, 성, 면역, 연, 구, 곤충, ...  \n",
       "9996  [토양, 및, 지하수, 의, 물리화학, 적, 특성, 에, 기반, 한, 제, 조, 나...  \n",
       "9997                         [보안, 과, 제, 정보보안, 과, 제, 정보]  \n",
       "9998  [혁신, 적, 콘텐츠, 산업, 발전, 을, 위, 한, CTCulture, techn...  \n",
       "9999  [자연, 지능, 및, 뇌, 질환, 의, 수학, 적, 모델, 에, 대한, 동, 특성,...  \n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df['contents'] = df['data'].apply(lambda x : text_preprocess(x))\n",
    "df['contents'] = df['contents'].progress_apply(lambda x: tokenize(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "sentences = df['contents'].values\n",
    "model = gensim.models.Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(model.wv.vocab)\n",
    "filename = '벡터.txt'\n",
    "model.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('', '벡터.txt'),  encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = int(len(df) *0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[:num, 'contents'].values\n",
    "y_train = df.loc[:num, 'label'].values\n",
    "X_test = df.loc[num:, 'contents'].values\n",
    "y_test = df.loc[num:, 'label'].values\n",
    "\n",
    "total_reviews = df.values\n",
    "max_length = 200\n",
    "review_lines = df['contents'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58962 unique tokens.\n",
      "Shape of review tensor: (10000, 200)\n",
      "Shape of sentiment tensor: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "# vectorize the text samples into a 2D integer tensor\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(review_lines)\n",
    "sequences = tokenizer_obj.texts_to_sequences(review_lines)\n",
    "\n",
    "# pad sequences\n",
    "word_index = tokenizer_obj.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "review_pad = pad_sequences(sequences, maxlen=max_length)\n",
    "rating =  df['label'].values\n",
    "print('Shape of review tensor:', review_pad.shape)\n",
    "print('Shape of sentiment tensor:', rating.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(review_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "review_pad = review_pad[indices]\n",
    "sentiment = rating[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * review_pad.shape[0])\n",
    "\n",
    "X_train_pad = review_pad[:-num_validation_samples]\n",
    "y_train = sentiment[:-num_validation_samples]\n",
    "X_test_pad = review_pad[-num_validation_samples:]\n",
    "y_test = sentiment[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58963\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 200, 100)          5896300   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 196, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 98, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 98, 128)           16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 98, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 46)                577070    \n",
      "=================================================================\n",
      "Total params: 6,554,010\n",
      "Trainable params: 657,710\n",
      "Non-trainable params: 5,896,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Embedding, Flatten, Dropout\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.python.keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.python.keras.initializers import Constant\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)\n",
    "\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.concatenate([y_train,y_test])\n",
    "Y\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 - 11s - loss: 0.0767 - accuracy: 0.9773 - val_loss: 1.4459 - val_accuracy: 0.8080\n",
      "Epoch 2/5\n",
      "9000/9000 - 11s - loss: 0.0418 - accuracy: 0.9871 - val_loss: 1.4648 - val_accuracy: 0.8080\n",
      "Epoch 3/5\n",
      "9000/9000 - 11s - loss: 0.0338 - accuracy: 0.9901 - val_loss: 1.5435 - val_accuracy: 0.8120\n",
      "Epoch 4/5\n",
      "9000/9000 - 11s - loss: 0.0288 - accuracy: 0.9919 - val_loss: 1.9329 - val_accuracy: 0.8140\n",
      "Epoch 5/5\n",
      "9000/9000 - 11s - loss: nan - accuracy: 0.9203 - val_loss: nan - val_accuracy: 0.8090\n",
      "training complete\n",
      "종료시간:  2021-07-05 21:56:01.310722 \n",
      "소요시간:  0:00:55.250762 \n",
      "\n",
      "\n",
      "1000/1000 [==============================] - 0s 417us/sample - loss: nan - accuracy: 0.8090\n",
      "Accuracy: 80.90 %\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "stime2 = datetime.datetime.now()\n",
    "print(\"training start\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "hist= model.fit(X_train_pad, dummy_y[:9000], batch_size=64, epochs=5, \n",
    "                validation_data=(X_test_pad, dummy_y[9000:]), verbose=2)\n",
    "\n",
    "etime2 = datetime.datetime.now()\n",
    "mtime2 = etime2-stime2\n",
    "\n",
    "print(\"training complete\")\n",
    "print(\"종료시간: \",etime2,\"\\n소요시간: \",mtime2,'\\n\\n')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_pad, dummy_y[9000:], batch_size=64)\n",
    "print('Accuracy: %.2f' % (accuracy*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "## BERT 모델: 메모리 부족으로 실행불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = list(zip(train.data, train.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61dd3e58faf4487951fde0f6a8c3a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6017a140e2483281a675a21297fd33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:79] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2642411520 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-684f3acd03f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1532\u001b[0m         )\n\u001b[0;32m   1533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    999\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1001\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1002\u001b[0m         )\n\u001b[0;32m   1003\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m                 )\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    473\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m             \u001b[0mpast_key_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         )\n\u001b[0;32m    477\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m         )\n\u001b[0;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"relative_key\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"relative_key_query\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:79] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2642411520 bytes."
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "itr = 1\n",
    "p_itr = 500\n",
    "epochs = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for text, label in new_train:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # encoding and zero padding\n",
    "        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "        \n",
    "        sample = torch.tensor(padded_list)\n",
    "        labels = torch.tensor(label)\n",
    "        outputs = model(sample, labels=labels)\n",
    "        loss, logits = outputs\n",
    "\n",
    "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        correct = pred.eq(labels)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(itr)\n",
    "        if itr % p_itr == 0:\n",
    "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "            total_loss = 0\n",
    "            total_len = 0\n",
    "            total_correct = 0\n",
    "\n",
    "        itr+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cls_model.predict(test_inputs)\n",
    "results=tf.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['label']=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('bert_baseline.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
