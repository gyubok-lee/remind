{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어처리 + 분류\n",
    "### 자연어 기반 기후기술분류 AI 경진대회 데이터 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score,f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from transformers import BertTokenizer, BertModel\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/open/'\n",
    "\n",
    "train=pd.read_csv(data_path + 'train.csv')\n",
    "test=pd.read_csv(data_path +'test.csv')\n",
    "sample_submission=pd.read_csv(data_path +'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[['과제명', '요약문_연구내용','label']]\n",
    "test=test[['과제명', '요약문_연구내용']]\n",
    "\n",
    "train['요약문_연구내용'].fillna('NAN', inplace=True)\n",
    "test['요약문_연구내용'].fillna('NAN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['data']=train['과제명']+train['요약문_연구내용']\n",
    "test['data']=test['과제명']+test['요약문_연구내용']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과제명</th>\n",
       "      <th>요약문_연구내용</th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발</td>\n",
       "      <td>(가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...</td>\n",
       "      <td>24</td>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "      <td>1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...</td>\n",
       "      <td>0</td>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "      <td>* 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...</td>\n",
       "      <td>0</td>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발</td>\n",
       "      <td># 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발# 소화기 암 진단용 분자영상 형광프로브 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사</td>\n",
       "      <td>-In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사-In situ hybridizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>재배안정성, 복합내병성 토마토 품종육성</td>\n",
       "      <td>- 토마토 유전자원의 탐색, 수집, 평가하여 육종소재 활용\\n\\n\\n  - 양친으로...</td>\n",
       "      <td>23</td>\n",
       "      <td>재배안정성, 복합내병성 토마토 품종육성- 토마토 유전자원의 탐색, 수집, 평가하여 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발</td>\n",
       "      <td>&amp;lt;주관기관 개발내용&amp;gt;\\n\\n\\n？ 가상현실 연동용 윈드블로워 개발\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발&amp;lt;주관기관 개발내용...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구</td>\n",
       "      <td>1차년도 혈관전구세포의 분화에 미치는 redox 단백질의 기능 연구\\n\\n1) iP...</td>\n",
       "      <td>0</td>\n",
       "      <td>혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구1차년도 혈관전구세포의 분...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>갈색날개매미충의 신호화학물질 개발 및 이용방법 연구</td>\n",
       "      <td>○ 외래해충 유인 및 기피물질 선발\\n\\n\\n ○ 선발된 유인물질과 기피물질의 작용...</td>\n",
       "      <td>24</td>\n",
       "      <td>갈색날개매미충의 신호화학물질 개발 및 이용방법 연구○ 외래해충 유인 및 기피물질 선...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>실시간 양방향 소통을 통한 학습지원 플랫폼</td>\n",
       "      <td>○ 일대일 질문방 개발\\n\\n\\n-실시간 양방향 소통을 통한 학습 지원 시스템   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>실시간 양방향 소통을 통한 학습지원 플랫폼○ 일대일 질문방 개발\\n\\n\\n-실시간 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     과제명  \\\n",
       "0                           유전정보를 활용한 새로운 해충 분류군 동정기술 개발   \n",
       "1      대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...   \n",
       "2      비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...   \n",
       "3                                소화기 암 진단용 분자영상 형광프로브 개발   \n",
       "4                            위암환자의 항암제반응예측을 위한 BRCA 발현검사   \n",
       "...                                                  ...   \n",
       "99995                              재배안정성, 복합내병성 토마토 품종육성   \n",
       "99996                  가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발   \n",
       "99997                   혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구   \n",
       "99998                       갈색날개매미충의 신호화학물질 개발 및 이용방법 연구   \n",
       "99999                            실시간 양방향 소통을 통한 학습지원 플랫폼   \n",
       "\n",
       "                                                요약문_연구내용  label  \\\n",
       "0      (가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...     24   \n",
       "1      1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...      0   \n",
       "2      * 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...      0   \n",
       "3      # 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...      0   \n",
       "4      -In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...      0   \n",
       "...                                                  ...    ...   \n",
       "99995  - 토마토 유전자원의 탐색, 수집, 평가하여 육종소재 활용\\n\\n\\n  - 양친으로...     23   \n",
       "99996  &lt;주관기관 개발내용&gt;\\n\\n\\n？ 가상현실 연동용 윈드블로워 개발\\n\\n...      0   \n",
       "99997  1차년도 혈관전구세포의 분화에 미치는 redox 단백질의 기능 연구\\n\\n1) iP...      0   \n",
       "99998  ○ 외래해충 유인 및 기피물질 선발\\n\\n\\n ○ 선발된 유인물질과 기피물질의 작용...     24   \n",
       "99999  ○ 일대일 질문방 개발\\n\\n\\n-실시간 양방향 소통을 통한 학습 지원 시스템   ...      0   \n",
       "\n",
       "                                                    data  \n",
       "0      유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...  \n",
       "1      대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...  \n",
       "2      비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...  \n",
       "3      소화기 암 진단용 분자영상 형광프로브 개발# 소화기 암 진단용 분자영상 형광프로브 ...  \n",
       "4      위암환자의 항암제반응예측을 위한 BRCA 발현검사-In situ hybridizat...  \n",
       "...                                                  ...  \n",
       "99995  재배안정성, 복합내병성 토마토 품종육성- 토마토 유전자원의 탐색, 수집, 평가하여 ...  \n",
       "99996  가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발&lt;주관기관 개발내용...  \n",
       "99997  혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구1차년도 혈관전구세포의 분...  \n",
       "99998  갈색날개매미충의 신호화학물질 개발 및 이용방법 연구○ 외래해충 유인 및 기피물질 선...  \n",
       "99999  실시간 양방향 소통을 통한 학습지원 플랫폼○ 일대일 질문방 개발\\n\\n\\n-실시간 ...  \n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.copy()\n",
    "\n",
    "df1 = df[:100000]\n",
    "df2 = df[100000:]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "def text_preprocess(x):\n",
    "    text=[]\n",
    "    a = re.sub('[^가-힣0-9a-zA-Z\\\\s]', '',x)\n",
    "    for j in a.split():\n",
    "        text.append(j)\n",
    "    return ' '.join(text)\n",
    "\n",
    "def tokenize(x):\n",
    "    text = []\n",
    "    tokens = okt.pos(x)\n",
    "    for token in tokens :\n",
    "        if token[1] == 'Adjective' or token[1]=='Adverb' or token[1] == 'Determiner' or token[1] == 'Noun' or token[1] == 'Verb' or 'Unknown':\n",
    "            text.append(token[0])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "100%|████████████████████████████████████████████████████████████████████████| 100000/100000 [1:40:42<00:00, 16.55it/s]\n",
      "c:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과제명</th>\n",
       "      <th>요약문_연구내용</th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발</td>\n",
       "      <td>(가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...</td>\n",
       "      <td>24</td>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...</td>\n",
       "      <td>[유전, 정보, 를, 활용, 한, 새로운, 해충, 분류군, 동정, 기술, 개발, 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "      <td>1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...</td>\n",
       "      <td>0</td>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "      <td>[대장암, 의, TRAIL, 내, 성, 표적, 인자, 발굴, 및, TRAIL, 반응...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "      <td>* 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...</td>\n",
       "      <td>0</td>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "      <td>[비목, 질계, 셀룰로오스, 식물, 자원, 을, 활용, 한, 기능, 성, 부직포, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발</td>\n",
       "      <td># 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발# 소화기 암 진단용 분자영상 형광프로브 ...</td>\n",
       "      <td>[소화기, 암, 진단, 용, 분자영상, 형광, 프로, 브, 개발, 소화기, 암, 진...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사</td>\n",
       "      <td>-In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사-In situ hybridizat...</td>\n",
       "      <td>[위암, 환자, 의, 항암제, 반응, 예측, 을, 위, 한, BRCA, 발현, 검사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>재배안정성, 복합내병성 토마토 품종육성</td>\n",
       "      <td>- 토마토 유전자원의 탐색, 수집, 평가하여 육종소재 활용\\n\\n\\n  - 양친으로...</td>\n",
       "      <td>23</td>\n",
       "      <td>재배안정성, 복합내병성 토마토 품종육성- 토마토 유전자원의 탐색, 수집, 평가하여 ...</td>\n",
       "      <td>[재배, 안정, 성, 복합, 내, 병, 성, 토마토, 품종, 육성, 토마토, 유전자...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발</td>\n",
       "      <td>&amp;lt;주관기관 개발내용&amp;gt;\\n\\n\\n？ 가상현실 연동용 윈드블로워 개발\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발&amp;lt;주관기관 개발내용...</td>\n",
       "      <td>[가상현실, 바람, 효과, 를, 재현, 하는, 에어, 블, 로, 워, 클러스터링, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구</td>\n",
       "      <td>1차년도 혈관전구세포의 분화에 미치는 redox 단백질의 기능 연구\\n\\n1) iP...</td>\n",
       "      <td>0</td>\n",
       "      <td>혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구1차년도 혈관전구세포의 분...</td>\n",
       "      <td>[혈관, 재협착, 을, 일으키는, 평활, 근, 전, 구, 세포, 의, REDOX, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>갈색날개매미충의 신호화학물질 개발 및 이용방법 연구</td>\n",
       "      <td>○ 외래해충 유인 및 기피물질 선발\\n\\n\\n ○ 선발된 유인물질과 기피물질의 작용...</td>\n",
       "      <td>24</td>\n",
       "      <td>갈색날개매미충의 신호화학물질 개발 및 이용방법 연구○ 외래해충 유인 및 기피물질 선...</td>\n",
       "      <td>[갈색, 날개, 매미, 충의, 신호, 화학물질, 개발, 및, 이용, 방법, 연구, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>실시간 양방향 소통을 통한 학습지원 플랫폼</td>\n",
       "      <td>○ 일대일 질문방 개발\\n\\n\\n-실시간 양방향 소통을 통한 학습 지원 시스템   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>실시간 양방향 소통을 통한 학습지원 플랫폼○ 일대일 질문방 개발\\n\\n\\n-실시간 ...</td>\n",
       "      <td>[실시간, 양, 방향, 소통, 을, 통한, 학습, 지원, 플랫폼, 일대일, 질문방,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     과제명  \\\n",
       "0                           유전정보를 활용한 새로운 해충 분류군 동정기술 개발   \n",
       "1      대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...   \n",
       "2      비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...   \n",
       "3                                소화기 암 진단용 분자영상 형광프로브 개발   \n",
       "4                            위암환자의 항암제반응예측을 위한 BRCA 발현검사   \n",
       "...                                                  ...   \n",
       "99995                              재배안정성, 복합내병성 토마토 품종육성   \n",
       "99996                  가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발   \n",
       "99997                   혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구   \n",
       "99998                       갈색날개매미충의 신호화학물질 개발 및 이용방법 연구   \n",
       "99999                            실시간 양방향 소통을 통한 학습지원 플랫폼   \n",
       "\n",
       "                                                요약문_연구내용  label  \\\n",
       "0      (가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...     24   \n",
       "1      1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...      0   \n",
       "2      * 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...      0   \n",
       "3      # 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...      0   \n",
       "4      -In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...      0   \n",
       "...                                                  ...    ...   \n",
       "99995  - 토마토 유전자원의 탐색, 수집, 평가하여 육종소재 활용\\n\\n\\n  - 양친으로...     23   \n",
       "99996  &lt;주관기관 개발내용&gt;\\n\\n\\n？ 가상현실 연동용 윈드블로워 개발\\n\\n...      0   \n",
       "99997  1차년도 혈관전구세포의 분화에 미치는 redox 단백질의 기능 연구\\n\\n1) iP...      0   \n",
       "99998  ○ 외래해충 유인 및 기피물질 선발\\n\\n\\n ○ 선발된 유인물질과 기피물질의 작용...     24   \n",
       "99999  ○ 일대일 질문방 개발\\n\\n\\n-실시간 양방향 소통을 통한 학습 지원 시스템   ...      0   \n",
       "\n",
       "                                                    data  \\\n",
       "0      유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...   \n",
       "1      대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...   \n",
       "2      비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...   \n",
       "3      소화기 암 진단용 분자영상 형광프로브 개발# 소화기 암 진단용 분자영상 형광프로브 ...   \n",
       "4      위암환자의 항암제반응예측을 위한 BRCA 발현검사-In situ hybridizat...   \n",
       "...                                                  ...   \n",
       "99995  재배안정성, 복합내병성 토마토 품종육성- 토마토 유전자원의 탐색, 수집, 평가하여 ...   \n",
       "99996  가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발&lt;주관기관 개발내용...   \n",
       "99997  혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구1차년도 혈관전구세포의 분...   \n",
       "99998  갈색날개매미충의 신호화학물질 개발 및 이용방법 연구○ 외래해충 유인 및 기피물질 선...   \n",
       "99999  실시간 양방향 소통을 통한 학습지원 플랫폼○ 일대일 질문방 개발\\n\\n\\n-실시간 ...   \n",
       "\n",
       "                                                contents  \n",
       "0      [유전, 정보, 를, 활용, 한, 새로운, 해충, 분류군, 동정, 기술, 개발, 가...  \n",
       "1      [대장암, 의, TRAIL, 내, 성, 표적, 인자, 발굴, 및, TRAIL, 반응...  \n",
       "2      [비목, 질계, 셀룰로오스, 식물, 자원, 을, 활용, 한, 기능, 성, 부직포, ...  \n",
       "3      [소화기, 암, 진단, 용, 분자영상, 형광, 프로, 브, 개발, 소화기, 암, 진...  \n",
       "4      [위암, 환자, 의, 항암제, 반응, 예측, 을, 위, 한, BRCA, 발현, 검사...  \n",
       "...                                                  ...  \n",
       "99995  [재배, 안정, 성, 복합, 내, 병, 성, 토마토, 품종, 육성, 토마토, 유전자...  \n",
       "99996  [가상현실, 바람, 효과, 를, 재현, 하는, 에어, 블, 로, 워, 클러스터링, ...  \n",
       "99997  [혈관, 재협착, 을, 일으키는, 평활, 근, 전, 구, 세포, 의, REDOX, ...  \n",
       "99998  [갈색, 날개, 매미, 충의, 신호, 화학물질, 개발, 및, 이용, 방법, 연구, ...  \n",
       "99999  [실시간, 양, 방향, 소통, 을, 통한, 학습, 지원, 플랫폼, 일대일, 질문방,...  \n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df1['contents'] = df1['data'].apply(lambda x : text_preprocess(x))\n",
    "df1['contents'] = df1['contents'].progress_apply(lambda x: tokenize(x))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"df1.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df1['contents'] = df1['data'].apply(lambda x : text_preprocess(x))\n",
    "df1['contents'] = df1['contents'].progress_apply(lambda x: tokenize(x))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "sentences = df['contents'].values\n",
    "model = gensim.models.Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(model.wv.vocab)\n",
    "filename = '벡터.txt'\n",
    "model.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('', '벡터.txt'),  encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = int(len(df) *0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[:num, 'contents'].values\n",
    "y_train = df.loc[:num, 'label'].values\n",
    "X_test = df.loc[num:, 'contents'].values\n",
    "y_test = df.loc[num:, 'label'].values\n",
    "\n",
    "total_reviews = df.values\n",
    "max_length = 200\n",
    "review_lines = df['contents'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 58962 unique tokens.\n",
      "Shape of review tensor: (10000, 200)\n",
      "Shape of sentiment tensor: (10000,)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "# vectorize the text samples into a 2D integer tensor\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(review_lines)\n",
    "sequences = tokenizer_obj.texts_to_sequences(review_lines)\n",
    "\n",
    "# pad sequences\n",
    "word_index = tokenizer_obj.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "review_pad = pad_sequences(sequences, maxlen=max_length)\n",
    "rating =  df['label'].values\n",
    "print('Shape of review tensor:', review_pad.shape)\n",
    "print('Shape of sentiment tensor:', rating.shape)\n",
    "\n",
    "# split the data into a training set and a validation set\n",
    "indices = np.arange(review_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "review_pad = review_pad[indices]\n",
    "sentiment = rating[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * review_pad.shape[0])\n",
    "\n",
    "X_train_pad = review_pad[:-num_validation_samples]\n",
    "y_train = sentiment[:-num_validation_samples]\n",
    "X_test_pad = review_pad[-num_validation_samples:]\n",
    "y_test = sentiment[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58963\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 200, 100)          5896300   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 196, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 98, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 98, 128)           16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 98, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 46)                577070    \n",
      "=================================================================\n",
      "Total params: 6,554,010\n",
      "Trainable params: 657,710\n",
      "Non-trainable params: 5,896,300\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Embedding, Flatten, Dropout\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.python.keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.python.keras.initializers import Constant\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)\n",
    "\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = np.concatenate([y_train,y_test])\n",
    "Y\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/5\n",
      "9000/9000 - 11s - loss: 0.0767 - accuracy: 0.9773 - val_loss: 1.4459 - val_accuracy: 0.8080\n",
      "Epoch 2/5\n",
      "9000/9000 - 11s - loss: 0.0418 - accuracy: 0.9871 - val_loss: 1.4648 - val_accuracy: 0.8080\n",
      "Epoch 3/5\n",
      "9000/9000 - 11s - loss: 0.0338 - accuracy: 0.9901 - val_loss: 1.5435 - val_accuracy: 0.8120\n",
      "Epoch 4/5\n",
      "9000/9000 - 11s - loss: 0.0288 - accuracy: 0.9919 - val_loss: 1.9329 - val_accuracy: 0.8140\n",
      "Epoch 5/5\n",
      "9000/9000 - 11s - loss: nan - accuracy: 0.9203 - val_loss: nan - val_accuracy: 0.8090\n",
      "training complete\n",
      "종료시간:  2021-07-05 21:56:01.310722 \n",
      "소요시간:  0:00:55.250762 \n",
      "\n",
      "\n",
      "1000/1000 [==============================] - 0s 417us/sample - loss: nan - accuracy: 0.8090\n",
      "Accuracy: 80.90 %\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "stime2 = datetime.datetime.now()\n",
    "print(\"training start\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "hist= model.fit(X_train_pad, dummy_y[:9000], batch_size=64, epochs=5, \n",
    "                validation_data=(X_test_pad, dummy_y[9000:]), verbose=2)\n",
    "\n",
    "etime2 = datetime.datetime.now()\n",
    "mtime2 = etime2-stime2\n",
    "\n",
    "print(\"training complete\")\n",
    "print(\"종료시간: \",etime2,\"\\n소요시간: \",mtime2,'\\n\\n')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_pad, dummy_y[9000:], batch_size=64)\n",
    "print('Accuracy: %.2f' % (accuracy*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "## BERT 모델: 메모리 부족으로 실행불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = list(zip(train.data, train.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61dd3e58faf4487951fde0f6a8c3a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6017a140e2483281a675a21297fd33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:79] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2642411520 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-684f3acd03f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1532\u001b[0m         )\n\u001b[0;32m   1533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    999\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1001\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1002\u001b[0m         )\n\u001b[0;32m   1003\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m                 )\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    473\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m             \u001b[0mpast_key_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         )\n\u001b[0;32m    477\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m         )\n\u001b[0;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"relative_key\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"relative_key_query\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:79] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2642411520 bytes."
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "itr = 1\n",
    "p_itr = 500\n",
    "epochs = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for text, label in new_train:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # encoding and zero padding\n",
    "        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "        \n",
    "        sample = torch.tensor(padded_list)\n",
    "        labels = torch.tensor(label)\n",
    "        outputs = model(sample, labels=labels)\n",
    "        loss, logits = outputs\n",
    "\n",
    "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        correct = pred.eq(labels)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(itr)\n",
    "        if itr % p_itr == 0:\n",
    "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "            total_loss = 0\n",
    "            total_len = 0\n",
    "            total_correct = 0\n",
    "\n",
    "        itr+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cls_model.predict(test_inputs)\n",
    "results=tf.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['label']=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('bert_baseline.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
