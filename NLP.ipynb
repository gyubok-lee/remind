{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 자연어처리 + 분류\n",
    "### 자연어 기반 기후기술분류 AI 경진대회 데이터 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 문장 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 & 라이브러리 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from ast import literal_eval\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import log_loss, accuracy_score,f1_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "#from transformers import BertTokenizer, BertModel\n",
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/open/'\n",
    "\n",
    "train=pd.read_csv(data_path + 'train.csv')\n",
    "test=pd.read_csv(data_path +'test.csv')\n",
    "sample_submission=pd.read_csv(data_path +'sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train[['과제명', '요약문_연구내용','label']]\n",
    "test=test[['과제명', '요약문_연구내용']]\n",
    "\n",
    "train['요약문_연구내용'].fillna('NAN', inplace=True)\n",
    "test['요약문_연구내용'].fillna('NAN', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['data']=train['과제명']+train['요약문_연구내용']\n",
    "test['data']=test['과제명']+test['요약문_연구내용']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과제명</th>\n",
       "      <th>요약문_연구내용</th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발</td>\n",
       "      <td>(가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...</td>\n",
       "      <td>24</td>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "      <td>1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...</td>\n",
       "      <td>0</td>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "      <td>* 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...</td>\n",
       "      <td>0</td>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발</td>\n",
       "      <td># 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발# 소화기 암 진단용 분자영상 형광프로브 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사</td>\n",
       "      <td>-In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사-In situ hybridizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>재배안정성, 복합내병성 토마토 품종육성</td>\n",
       "      <td>- 토마토 유전자원의 탐색, 수집, 평가하여 육종소재 활용\\n\\n\\n  - 양친으로...</td>\n",
       "      <td>23</td>\n",
       "      <td>재배안정성, 복합내병성 토마토 품종육성- 토마토 유전자원의 탐색, 수집, 평가하여 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발</td>\n",
       "      <td>&amp;lt;주관기관 개발내용&amp;gt;\\n\\n\\n？ 가상현실 연동용 윈드블로워 개발\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발&amp;lt;주관기관 개발내용...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구</td>\n",
       "      <td>1차년도 혈관전구세포의 분화에 미치는 redox 단백질의 기능 연구\\n\\n1) iP...</td>\n",
       "      <td>0</td>\n",
       "      <td>혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구1차년도 혈관전구세포의 분...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>갈색날개매미충의 신호화학물질 개발 및 이용방법 연구</td>\n",
       "      <td>○ 외래해충 유인 및 기피물질 선발\\n\\n\\n ○ 선발된 유인물질과 기피물질의 작용...</td>\n",
       "      <td>24</td>\n",
       "      <td>갈색날개매미충의 신호화학물질 개발 및 이용방법 연구○ 외래해충 유인 및 기피물질 선...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>실시간 양방향 소통을 통한 학습지원 플랫폼</td>\n",
       "      <td>○ 일대일 질문방 개발\\n\\n\\n-실시간 양방향 소통을 통한 학습 지원 시스템   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>실시간 양방향 소통을 통한 학습지원 플랫폼○ 일대일 질문방 개발\\n\\n\\n-실시간 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     과제명  \\\n",
       "0                           유전정보를 활용한 새로운 해충 분류군 동정기술 개발   \n",
       "1      대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...   \n",
       "2      비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...   \n",
       "3                                소화기 암 진단용 분자영상 형광프로브 개발   \n",
       "4                            위암환자의 항암제반응예측을 위한 BRCA 발현검사   \n",
       "...                                                  ...   \n",
       "99995                              재배안정성, 복합내병성 토마토 품종육성   \n",
       "99996                  가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발   \n",
       "99997                   혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구   \n",
       "99998                       갈색날개매미충의 신호화학물질 개발 및 이용방법 연구   \n",
       "99999                            실시간 양방향 소통을 통한 학습지원 플랫폼   \n",
       "\n",
       "                                                요약문_연구내용  label  \\\n",
       "0      (가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...     24   \n",
       "1      1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...      0   \n",
       "2      * 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...      0   \n",
       "3      # 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...      0   \n",
       "4      -In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...      0   \n",
       "...                                                  ...    ...   \n",
       "99995  - 토마토 유전자원의 탐색, 수집, 평가하여 육종소재 활용\\n\\n\\n  - 양친으로...     23   \n",
       "99996  &lt;주관기관 개발내용&gt;\\n\\n\\n？ 가상현실 연동용 윈드블로워 개발\\n\\n...      0   \n",
       "99997  1차년도 혈관전구세포의 분화에 미치는 redox 단백질의 기능 연구\\n\\n1) iP...      0   \n",
       "99998  ○ 외래해충 유인 및 기피물질 선발\\n\\n\\n ○ 선발된 유인물질과 기피물질의 작용...     24   \n",
       "99999  ○ 일대일 질문방 개발\\n\\n\\n-실시간 양방향 소통을 통한 학습 지원 시스템   ...      0   \n",
       "\n",
       "                                                    data  \n",
       "0      유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...  \n",
       "1      대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...  \n",
       "2      비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...  \n",
       "3      소화기 암 진단용 분자영상 형광프로브 개발# 소화기 암 진단용 분자영상 형광프로브 ...  \n",
       "4      위암환자의 항암제반응예측을 위한 BRCA 발현검사-In situ hybridizat...  \n",
       "...                                                  ...  \n",
       "99995  재배안정성, 복합내병성 토마토 품종육성- 토마토 유전자원의 탐색, 수집, 평가하여 ...  \n",
       "99996  가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발&lt;주관기관 개발내용...  \n",
       "99997  혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구1차년도 혈관전구세포의 분...  \n",
       "99998  갈색날개매미충의 신호화학물질 개발 및 이용방법 연구○ 외래해충 유인 및 기피물질 선...  \n",
       "99999  실시간 양방향 소통을 통한 학습지원 플랫폼○ 일대일 질문방 개발\\n\\n\\n-실시간 ...  \n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.copy()\n",
    "\n",
    "# 데이터 용량이 매우 커 두 개로 나눔\n",
    "df1 = df[:100000]\n",
    "df2 = df[100000:]\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "\n",
    "def text_preprocess(x):\n",
    "    text=[]\n",
    "    a = re.sub('[^가-힣0-9a-zA-Z\\\\s]', '',x)\n",
    "    for j in a.split():\n",
    "        text.append(j)\n",
    "    return ' '.join(text)\n",
    "\n",
    "def tokenize(x):\n",
    "    text = []\n",
    "    tokens = okt.pos(x)\n",
    "    for token in tokens :\n",
    "        if token[1] == 'Adjective' or token[1]=='Adverb' or token[1] == 'Determiner' or token[1] == 'Noun' or token[1] == 'Verb' or 'Unknown':\n",
    "            text.append(token[0])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "100%|████████████████████████████████████████████████████████████████████████| 100000/100000 [1:40:42<00:00, 16.55it/s]\n",
      "c:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과제명</th>\n",
       "      <th>요약문_연구내용</th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발</td>\n",
       "      <td>(가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...</td>\n",
       "      <td>24</td>\n",
       "      <td>유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...</td>\n",
       "      <td>[유전, 정보, 를, 활용, 한, 새로운, 해충, 분류군, 동정, 기술, 개발, 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "      <td>1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...</td>\n",
       "      <td>0</td>\n",
       "      <td>대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...</td>\n",
       "      <td>[대장암, 의, TRAIL, 내, 성, 표적, 인자, 발굴, 및, TRAIL, 반응...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "      <td>* 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...</td>\n",
       "      <td>0</td>\n",
       "      <td>비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...</td>\n",
       "      <td>[비목, 질계, 셀룰로오스, 식물, 자원, 을, 활용, 한, 기능, 성, 부직포, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발</td>\n",
       "      <td># 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>소화기 암 진단용 분자영상 형광프로브 개발# 소화기 암 진단용 분자영상 형광프로브 ...</td>\n",
       "      <td>[소화기, 암, 진단, 용, 분자영상, 형광, 프로, 브, 개발, 소화기, 암, 진...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사</td>\n",
       "      <td>-In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>위암환자의 항암제반응예측을 위한 BRCA 발현검사-In situ hybridizat...</td>\n",
       "      <td>[위암, 환자, 의, 항암제, 반응, 예측, 을, 위, 한, BRCA, 발현, 검사...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>재배안정성, 복합내병성 토마토 품종육성</td>\n",
       "      <td>- 토마토 유전자원의 탐색, 수집, 평가하여 육종소재 활용\\n\\n\\n  - 양친으로...</td>\n",
       "      <td>23</td>\n",
       "      <td>재배안정성, 복합내병성 토마토 품종육성- 토마토 유전자원의 탐색, 수집, 평가하여 ...</td>\n",
       "      <td>[재배, 안정, 성, 복합, 내, 병, 성, 토마토, 품종, 육성, 토마토, 유전자...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발</td>\n",
       "      <td>&amp;lt;주관기관 개발내용&amp;gt;\\n\\n\\n？ 가상현실 연동용 윈드블로워 개발\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발&amp;lt;주관기관 개발내용...</td>\n",
       "      <td>[가상현실, 바람, 효과, 를, 재현, 하는, 에어, 블, 로, 워, 클러스터링, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구</td>\n",
       "      <td>1차년도 혈관전구세포의 분화에 미치는 redox 단백질의 기능 연구\\n\\n1) iP...</td>\n",
       "      <td>0</td>\n",
       "      <td>혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구1차년도 혈관전구세포의 분...</td>\n",
       "      <td>[혈관, 재협착, 을, 일으키는, 평활, 근, 전, 구, 세포, 의, REDOX, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>갈색날개매미충의 신호화학물질 개발 및 이용방법 연구</td>\n",
       "      <td>○ 외래해충 유인 및 기피물질 선발\\n\\n\\n ○ 선발된 유인물질과 기피물질의 작용...</td>\n",
       "      <td>24</td>\n",
       "      <td>갈색날개매미충의 신호화학물질 개발 및 이용방법 연구○ 외래해충 유인 및 기피물질 선...</td>\n",
       "      <td>[갈색, 날개, 매미, 충의, 신호, 화학물질, 개발, 및, 이용, 방법, 연구, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>실시간 양방향 소통을 통한 학습지원 플랫폼</td>\n",
       "      <td>○ 일대일 질문방 개발\\n\\n\\n-실시간 양방향 소통을 통한 학습 지원 시스템   ...</td>\n",
       "      <td>0</td>\n",
       "      <td>실시간 양방향 소통을 통한 학습지원 플랫폼○ 일대일 질문방 개발\\n\\n\\n-실시간 ...</td>\n",
       "      <td>[실시간, 양, 방향, 소통, 을, 통한, 학습, 지원, 플랫폼, 일대일, 질문방,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     과제명  \\\n",
       "0                           유전정보를 활용한 새로운 해충 분류군 동정기술 개발   \n",
       "1      대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...   \n",
       "2      비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...   \n",
       "3                                소화기 암 진단용 분자영상 형광프로브 개발   \n",
       "4                            위암환자의 항암제반응예측을 위한 BRCA 발현검사   \n",
       "...                                                  ...   \n",
       "99995                              재배안정성, 복합내병성 토마토 품종육성   \n",
       "99996                  가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발   \n",
       "99997                   혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구   \n",
       "99998                       갈색날개매미충의 신호화학물질 개발 및 이용방법 연구   \n",
       "99999                            실시간 양방향 소통을 통한 학습지원 플랫폼   \n",
       "\n",
       "                                                요약문_연구내용  label  \\\n",
       "0      (가) 외래 및 돌발해충의 발생조사 및 종 동정\\n\\n\\n    ○ 대상해충 : 최...     24   \n",
       "1      1차년도\\n1) Microarray를 통한 선천적 TRAIL 내성 표적 후보 유전자...      0   \n",
       "2      * 식물계자원 정련 및 최적 신서란 파이버 기초연구 개발\\n\\n\\n- Tencel/...      0   \n",
       "3      # 소화기 암 진단용 분자영상 형광프로브 개발\\n\\n\\n- 국소 도포형 소화기 암 ...      0   \n",
       "4      -In situ hybridization 검사의 정확성을 확인하기 위해 위암세포주 ...      0   \n",
       "...                                                  ...    ...   \n",
       "99995  - 토마토 유전자원의 탐색, 수집, 평가하여 육종소재 활용\\n\\n\\n  - 양친으로...     23   \n",
       "99996  &lt;주관기관 개발내용&gt;\\n\\n\\n？ 가상현실 연동용 윈드블로워 개발\\n\\n...      0   \n",
       "99997  1차년도 혈관전구세포의 분화에 미치는 redox 단백질의 기능 연구\\n\\n1) iP...      0   \n",
       "99998  ○ 외래해충 유인 및 기피물질 선발\\n\\n\\n ○ 선발된 유인물질과 기피물질의 작용...     24   \n",
       "99999  ○ 일대일 질문방 개발\\n\\n\\n-실시간 양방향 소통을 통한 학습 지원 시스템   ...      0   \n",
       "\n",
       "                                                    data  \\\n",
       "0      유전정보를 활용한 새로운 해충 분류군 동정기술 개발(가) 외래 및 돌발해충의 발생조...   \n",
       "1      대장암의 TRAIL 내성 표적 인자 발굴 및 TRAIL 반응 예측 유전자 지도 구축...   \n",
       "2      비목질계 셀룰로오스 식물자원을 활용한 기능성 부직포 및 고부가가치 뷰티케어 faci...   \n",
       "3      소화기 암 진단용 분자영상 형광프로브 개발# 소화기 암 진단용 분자영상 형광프로브 ...   \n",
       "4      위암환자의 항암제반응예측을 위한 BRCA 발현검사-In situ hybridizat...   \n",
       "...                                                  ...   \n",
       "99995  재배안정성, 복합내병성 토마토 품종육성- 토마토 유전자원의 탐색, 수집, 평가하여 ...   \n",
       "99996  가상현실 바람효과를 재현하는 에어블로워 클러스터링 기술 개발&lt;주관기관 개발내용...   \n",
       "99997  혈관재협착을 일으키는 평활근전구세포의 REDOX 반응 연구1차년도 혈관전구세포의 분...   \n",
       "99998  갈색날개매미충의 신호화학물질 개발 및 이용방법 연구○ 외래해충 유인 및 기피물질 선...   \n",
       "99999  실시간 양방향 소통을 통한 학습지원 플랫폼○ 일대일 질문방 개발\\n\\n\\n-실시간 ...   \n",
       "\n",
       "                                                contents  \n",
       "0      [유전, 정보, 를, 활용, 한, 새로운, 해충, 분류군, 동정, 기술, 개발, 가...  \n",
       "1      [대장암, 의, TRAIL, 내, 성, 표적, 인자, 발굴, 및, TRAIL, 반응...  \n",
       "2      [비목, 질계, 셀룰로오스, 식물, 자원, 을, 활용, 한, 기능, 성, 부직포, ...  \n",
       "3      [소화기, 암, 진단, 용, 분자영상, 형광, 프로, 브, 개발, 소화기, 암, 진...  \n",
       "4      [위암, 환자, 의, 항암제, 반응, 예측, 을, 위, 한, BRCA, 발현, 검사...  \n",
       "...                                                  ...  \n",
       "99995  [재배, 안정, 성, 복합, 내, 병, 성, 토마토, 품종, 육성, 토마토, 유전자...  \n",
       "99996  [가상현실, 바람, 효과, 를, 재현, 하는, 에어, 블, 로, 워, 클러스터링, ...  \n",
       "99997  [혈관, 재협착, 을, 일으키는, 평활, 근, 전, 구, 세포, 의, REDOX, ...  \n",
       "99998  [갈색, 날개, 매미, 충의, 신호, 화학물질, 개발, 및, 이용, 방법, 연구, ...  \n",
       "99999  [실시간, 양, 방향, 소통, 을, 통한, 학습, 지원, 플랫폼, 일대일, 질문방,...  \n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df1['contents'] = df1['data'].apply(lambda x : text_preprocess(x))\n",
    "df1['contents'] = df1['contents'].progress_apply(lambda x: tokenize(x))\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "100%|████████████████████████████████████████████████████████████████████████████| 74304/74304 [55:24<00:00, 22.35it/s]\n",
      "c:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과제명</th>\n",
       "      <th>요약문_연구내용</th>\n",
       "      <th>label</th>\n",
       "      <th>data</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100000</th>\n",
       "      <td>생산성 향상을 위한 천연광물 추출물을 이용한 양돈용 액상 단미사료의 개발</td>\n",
       "      <td>？천연 광물 추출물 양돈 전용 미네랄 단미사료 개발\\n\\n\\n - 추출 광물질(세리...</td>\n",
       "      <td>0</td>\n",
       "      <td>생산성 향상을 위한 천연광물 추출물을 이용한 양돈용 액상 단미사료의 개발？천연 광물...</td>\n",
       "      <td>[생산, 성, 향상, 을, 위, 한, 천연, 광물, 추출, 물, 을, 이용, 한, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100001</th>\n",
       "      <td>수출단감 생산을 위한 관비재배 기술 개발</td>\n",
       "      <td>(시험1) 수출단감 관비재배 가능성 구명\\n\\n\\n   시험품종 : ‘부유’\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>수출단감 생산을 위한 관비재배 기술 개발(시험1) 수출단감 관비재배 가능성 구명\\n...</td>\n",
       "      <td>[수출, 단감, 생산, 을, 위, 한, 관비, 재배, 기술, 개발, 시험, 1, 수...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100002</th>\n",
       "      <td>환자 안전 및 진료 효과성 제고를 위한 프로세스 지능화 및 진료 의사결정지원 기술 개발</td>\n",
       "      <td>1단계 연구 목표 및 내용 - 의료기관 프로세스 관리 운영 최적화 기술 개발\\n\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>환자 안전 및 진료 효과성 제고를 위한 프로세스 지능화 및 진료 의사결정지원 기술 ...</td>\n",
       "      <td>[환자, 안전, 및, 진료, 효과, 성, 제, 고, 를, 위, 한, 프로세스, 지능...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100003</th>\n",
       "      <td>식품자원의 비타민 A, E 및 K 성분 DB 구축</td>\n",
       "      <td>□ 시료를 분석하기 전에 표준물질 (CRM 또는 SRM)을 이용하여 각 분석항목별 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>식품자원의 비타민 A, E 및 K 성분 DB 구축□ 시료를 분석하기 전에 표준물질 ...</td>\n",
       "      <td>[식품, 자원, 의, 비타민, A, E, 및, K, 성분, DB, 구축, 시료, 를...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100004</th>\n",
       "      <td>현장계측 진동모드해석을 통한 케이슨 방파제의 구조성능 평가 기술</td>\n",
       "      <td>◦ 본 연구는 2년의 연구기간으로서 각 연차별 주요 연구내용은 다음과 같음.\\n◦ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>현장계측 진동모드해석을 통한 케이슨 방파제의 구조성능 평가 기술◦ 본 연구는 2년의...</td>\n",
       "      <td>[현, 장계, 측, 진동, 모드, 해석, 을, 통한, 케이슨, 방파제, 의, 구조,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174299</th>\n",
       "      <td>혈관내막 증식을 치료하기 위한 표적분자 발굴</td>\n",
       "      <td>● 1차년: 혈관내막 증식과 관련된 표적분자 발굴 및 염증세포의 활성과 분화에 대한...</td>\n",
       "      <td>0</td>\n",
       "      <td>혈관내막 증식을 치료하기 위한 표적분자 발굴● 1차년: 혈관내막 증식과 관련된 표적...</td>\n",
       "      <td>[혈관, 내막, 증식, 을, 치료, 하기, 위, 한, 표적, 분자, 발굴, 1, 차...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174300</th>\n",
       "      <td>삼킴곤란 개선을 위한 물성조절 식품시스템에서의 유동층과립 복합소재의 유변물성 변화 ...</td>\n",
       "      <td>본 연구에서는 여러 가지 유변물성 측정기술을 이용하여 고령자의 삼킴곤란 개선을 위해...</td>\n",
       "      <td>0</td>\n",
       "      <td>삼킴곤란 개선을 위한 물성조절 식품시스템에서의 유동층과립 복합소재의 유변물성 변화 ...</td>\n",
       "      <td>[삼킴, 곤란, 개선, 을, 위, 한, 물성, 조절, 식품, 시스템, 에서의, 유동...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174301</th>\n",
       "      <td>식물 유전체 정보 고도화 및 핵심 유전자 군 진화연구</td>\n",
       "      <td>○ 공개된 식물 유전체 정보 및 대상 유전자 군 선발\\n\\n   - 공개된 식물 유...</td>\n",
       "      <td>0</td>\n",
       "      <td>식물 유전체 정보 고도화 및 핵심 유전자 군 진화연구○ 공개된 식물 유전체 정보 및...</td>\n",
       "      <td>[식물, 유전체, 정보, 고도화, 및, 핵심, 유전자, 군, 진화, 연구, 공개, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174302</th>\n",
       "      <td>콩 유전자원 내건성, 내습성 대량평가 체계구축 및 자원선발</td>\n",
       "      <td>[1차 년도(2019)] \\n\\n1) 내건 및 내습성 유전자원 수집\\n\\n○ 기존 ...</td>\n",
       "      <td>23</td>\n",
       "      <td>콩 유전자원 내건성, 내습성 대량평가 체계구축 및 자원선발[1차 년도(2019)] ...</td>\n",
       "      <td>[콩, 유전자, 원, 내, 건성, 내, 습성, 대량, 평가, 체계, 구축, 및, 자...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174303</th>\n",
       "      <td>광학적 위상 제어 기법을 적용한 디지털 홀로그래피 현미경 시스템 개발</td>\n",
       "      <td>◦ 1차년도 연구개발 내용\\n   : 광섬유 비선형 굴절률 변화 효과를 이용한 광학...</td>\n",
       "      <td>0</td>\n",
       "      <td>광학적 위상 제어 기법을 적용한 디지털 홀로그래피 현미경 시스템 개발◦ 1차년도 연...</td>\n",
       "      <td>[광학, 적, 위상, 제어, 기법, 을, 적용, 한, 디지털, 홀로그래피, 현미경,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74304 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      과제명  \\\n",
       "100000           생산성 향상을 위한 천연광물 추출물을 이용한 양돈용 액상 단미사료의 개발   \n",
       "100001                             수출단감 생산을 위한 관비재배 기술 개발   \n",
       "100002   환자 안전 및 진료 효과성 제고를 위한 프로세스 지능화 및 진료 의사결정지원 기술 개발   \n",
       "100003                        식품자원의 비타민 A, E 및 K 성분 DB 구축   \n",
       "100004                현장계측 진동모드해석을 통한 케이슨 방파제의 구조성능 평가 기술   \n",
       "...                                                   ...   \n",
       "174299                           혈관내막 증식을 치료하기 위한 표적분자 발굴   \n",
       "174300  삼킴곤란 개선을 위한 물성조절 식품시스템에서의 유동층과립 복합소재의 유변물성 변화 ...   \n",
       "174301                      식물 유전체 정보 고도화 및 핵심 유전자 군 진화연구   \n",
       "174302                   콩 유전자원 내건성, 내습성 대량평가 체계구축 및 자원선발   \n",
       "174303             광학적 위상 제어 기법을 적용한 디지털 홀로그래피 현미경 시스템 개발   \n",
       "\n",
       "                                                 요약문_연구내용  label  \\\n",
       "100000  ？천연 광물 추출물 양돈 전용 미네랄 단미사료 개발\\n\\n\\n - 추출 광물질(세리...      0   \n",
       "100001  (시험1) 수출단감 관비재배 가능성 구명\\n\\n\\n   시험품종 : ‘부유’\\n\\n...      0   \n",
       "100002  1단계 연구 목표 및 내용 - 의료기관 프로세스 관리 운영 최적화 기술 개발\\n\\n...      0   \n",
       "100003  □ 시료를 분석하기 전에 표준물질 (CRM 또는 SRM)을 이용하여 각 분석항목별 ...      0   \n",
       "100004  ◦ 본 연구는 2년의 연구기간으로서 각 연차별 주요 연구내용은 다음과 같음.\\n◦ ...      0   \n",
       "...                                                   ...    ...   \n",
       "174299  ● 1차년: 혈관내막 증식과 관련된 표적분자 발굴 및 염증세포의 활성과 분화에 대한...      0   \n",
       "174300  본 연구에서는 여러 가지 유변물성 측정기술을 이용하여 고령자의 삼킴곤란 개선을 위해...      0   \n",
       "174301  ○ 공개된 식물 유전체 정보 및 대상 유전자 군 선발\\n\\n   - 공개된 식물 유...      0   \n",
       "174302  [1차 년도(2019)] \\n\\n1) 내건 및 내습성 유전자원 수집\\n\\n○ 기존 ...     23   \n",
       "174303  ◦ 1차년도 연구개발 내용\\n   : 광섬유 비선형 굴절률 변화 효과를 이용한 광학...      0   \n",
       "\n",
       "                                                     data  \\\n",
       "100000  생산성 향상을 위한 천연광물 추출물을 이용한 양돈용 액상 단미사료의 개발？천연 광물...   \n",
       "100001  수출단감 생산을 위한 관비재배 기술 개발(시험1) 수출단감 관비재배 가능성 구명\\n...   \n",
       "100002  환자 안전 및 진료 효과성 제고를 위한 프로세스 지능화 및 진료 의사결정지원 기술 ...   \n",
       "100003  식품자원의 비타민 A, E 및 K 성분 DB 구축□ 시료를 분석하기 전에 표준물질 ...   \n",
       "100004  현장계측 진동모드해석을 통한 케이슨 방파제의 구조성능 평가 기술◦ 본 연구는 2년의...   \n",
       "...                                                   ...   \n",
       "174299  혈관내막 증식을 치료하기 위한 표적분자 발굴● 1차년: 혈관내막 증식과 관련된 표적...   \n",
       "174300  삼킴곤란 개선을 위한 물성조절 식품시스템에서의 유동층과립 복합소재의 유변물성 변화 ...   \n",
       "174301  식물 유전체 정보 고도화 및 핵심 유전자 군 진화연구○ 공개된 식물 유전체 정보 및...   \n",
       "174302  콩 유전자원 내건성, 내습성 대량평가 체계구축 및 자원선발[1차 년도(2019)] ...   \n",
       "174303  광학적 위상 제어 기법을 적용한 디지털 홀로그래피 현미경 시스템 개발◦ 1차년도 연...   \n",
       "\n",
       "                                                 contents  \n",
       "100000  [생산, 성, 향상, 을, 위, 한, 천연, 광물, 추출, 물, 을, 이용, 한, ...  \n",
       "100001  [수출, 단감, 생산, 을, 위, 한, 관비, 재배, 기술, 개발, 시험, 1, 수...  \n",
       "100002  [환자, 안전, 및, 진료, 효과, 성, 제, 고, 를, 위, 한, 프로세스, 지능...  \n",
       "100003  [식품, 자원, 의, 비타민, A, E, 및, K, 성분, DB, 구축, 시료, 를...  \n",
       "100004  [현, 장계, 측, 진동, 모드, 해석, 을, 통한, 케이슨, 방파제, 의, 구조,...  \n",
       "...                                                   ...  \n",
       "174299  [혈관, 내막, 증식, 을, 치료, 하기, 위, 한, 표적, 분자, 발굴, 1, 차...  \n",
       "174300  [삼킴, 곤란, 개선, 을, 위, 한, 물성, 조절, 식품, 시스템, 에서의, 유동...  \n",
       "174301  [식물, 유전체, 정보, 고도화, 및, 핵심, 유전자, 군, 진화, 연구, 공개, ...  \n",
       "174302  [콩, 유전자, 원, 내, 건성, 내, 습성, 대량, 평가, 체계, 구축, 및, 자...  \n",
       "174303  [광학, 적, 위상, 제어, 기법, 을, 적용, 한, 디지털, 홀로그래피, 현미경,...  \n",
       "\n",
       "[74304 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df2['contents'] = df2['data'].apply(lambda x : text_preprocess(x))\n",
    "df2['contents'] = df2['contents'].progress_apply(lambda x: tokenize(x))\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contents</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['유전', '정보', '를', '활용', '한', '새로운', '해충', '분류군...</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['대장암', '의', 'TRAIL', '내', '성', '표적', '인자', '발...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['비목', '질계', '셀룰로오스', '식물', '자원', '을', '활용', '...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['소화기', '암', '진단', '용', '분자영상', '형광', '프로', '브...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['위암', '환자', '의', '항암제', '반응', '예측', '을', '위',...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217875</th>\n",
       "      <td>[포장, 용, 인, 디케이, 팅, 잉크, 제조, 기술, 개발, 및, 인쇄, 공정, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217876</th>\n",
       "      <td>[루시아, 신, 속, 정확, 저렴한, 현장, 진단, 용, 혁신, 적, 혈액, 진단,...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217877</th>\n",
       "      <td>[ITER, 삼중수소, 저장, 공급, DU, 용기, 개발, 및, 시험, ITER, ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217878</th>\n",
       "      <td>[무결, 정립, 계, 금속, 초, 박막, 의, 제조, 및, 이를, 활용, 한, 기초...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217879</th>\n",
       "      <td>[산업, 용, M, 30, SUS, Bolt, 의, 생산, 성, 향상, 제조, 기술...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>217880 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 contents  label\n",
       "0       ['유전', '정보', '를', '활용', '한', '새로운', '해충', '분류군...   24.0\n",
       "1       ['대장암', '의', 'TRAIL', '내', '성', '표적', '인자', '발...    0.0\n",
       "2       ['비목', '질계', '셀룰로오스', '식물', '자원', '을', '활용', '...    0.0\n",
       "3       ['소화기', '암', '진단', '용', '분자영상', '형광', '프로', '브...    0.0\n",
       "4       ['위암', '환자', '의', '항암제', '반응', '예측', '을', '위',...    0.0\n",
       "...                                                   ...    ...\n",
       "217875  [포장, 용, 인, 디케이, 팅, 잉크, 제조, 기술, 개발, 및, 인쇄, 공정, ...    NaN\n",
       "217876  [루시아, 신, 속, 정확, 저렴한, 현장, 진단, 용, 혁신, 적, 혈액, 진단,...    NaN\n",
       "217877  [ITER, 삼중수소, 저장, 공급, DU, 용기, 개발, 및, 시험, ITER, ...    NaN\n",
       "217878  [무결, 정립, 계, 금속, 초, 박막, 의, 제조, 및, 이를, 활용, 한, 기초...    NaN\n",
       "217879  [산업, 용, M, 30, SUS, Bolt, 의, 생산, 성, 향상, 제조, 기술...    NaN\n",
       "\n",
       "[217880 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.concat([df1,df2,test]).reset_index(drop = True)[['contents','label']]\n",
    "final_df.to_csv(\"final_df2.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 모델링 & 학습 및 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "df = final_df\n",
    "sentences = df['contents'].values\n",
    "model = gensim.models.Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(model.wv.vocab)\n",
    "filename = '벡터.txt'\n",
    "model.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('', '벡터.txt'),  encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "seperation = 174304 \n",
    "num = int(seperation *0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[:seperation , 'contents'].values\n",
    "y_train = df.loc[:seperation, 'label'].values\n",
    "\n",
    "#X_val = df.loc[num:seperation , 'contents'].values\n",
    "#y_val = df.loc[num:seperation , 'label'].values\n",
    "\n",
    "X_test = df.loc[seperation:, 'contents'].values\n",
    "y_test = df.loc[seperation:, 'label'].values\n",
    "\n",
    "total_reviews = df.values\n",
    "max_length = 200\n",
    "sentences = final_df['contents'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 354848 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "VALIDATION_SPLIT = 0.15\n",
    "\n",
    "# 벡터화\n",
    "tokenizer_obj = Tokenizer()\n",
    "tokenizer_obj.fit_on_texts(sentences)\n",
    "sequences = tokenizer_obj.texts_to_sequences(sentences)\n",
    "\n",
    "# 문장 패딩\n",
    "word_index = tokenizer_obj.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "sentences_pad = pad_sequences(sequences, maxlen=max_length)\n",
    "labels =  df['label'].values\n",
    "\n",
    "train_review_pad = sentences_pad[:seperation]\n",
    "test_review_pad = sentences_pad[seperation:]\n",
    "train_rating = labels[:seperation]\n",
    "\n",
    "\n",
    "# train/val set으로 나누기\n",
    "indices = np.arange(train_review_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_review_pad = train_review_pad[indices]\n",
    "Ys = train_rating[indices]\n",
    "num_validation_samples = int(VALIDATION_SPLIT * train_review_pad.shape[0])\n",
    "\n",
    "X_train_pad = train_review_pad[:-num_validation_samples]\n",
    "y_train = Ys[:-num_validation_samples]\n",
    "X_test_pad = train_review_pad[-num_validation_samples:]\n",
    "y_test = Ys[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354849\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 200, 100)          35484900  \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 196, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 98, 128)           0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 98, 128)           16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 98, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 46)                577070    \n",
      "=================================================================\n",
      "Total params: 36,142,610\n",
      "Trainable params: 657,710\n",
      "Non-trainable params: 35,484,900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Embedding, Flatten, Dropout\n",
    "from tensorflow.python.keras.layers.convolutional import Conv1D\n",
    "from tensorflow.python.keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.python.keras.initializers import Constant\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# load pre-trained word embeddings into an Embedding layer\n",
    "# note that we set trainable = False so as to keep the embeddings fixed\n",
    "embedding_layer = Embedding(num_words,\n",
    "                            EMBEDDING_DIM,\n",
    "                            embeddings_initializer=Constant(embedding_matrix),\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)\n",
    "\n",
    "model.add(embedding_layer)\n",
    "\n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(46, activation='sigmoid'))\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "\n",
    "Y = np.concatenate([y_train,y_test])\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "y_train = dummy_y[:-num_validation_samples]\n",
    "y_val = dummy_y[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "Train on 148159 samples, validate on 26145 samples\n",
      "Epoch 1/5\n",
      "148159/148159 - 193s - loss: 2.9755 - accuracy: 0.8179 - val_loss: 2.1773 - val_accuracy: 0.8183\n",
      "Epoch 2/5\n",
      "148159/148159 - 185s - loss: 1.6562 - accuracy: 0.8179 - val_loss: 1.3027 - val_accuracy: 0.8183\n",
      "Epoch 3/5\n",
      "148159/148159 - 191s - loss: 1.1781 - accuracy: 0.8179 - val_loss: 1.1058 - val_accuracy: 0.8183\n",
      "Epoch 4/5\n",
      "148159/148159 - 191s - loss: 1.0862 - accuracy: 0.8179 - val_loss: 1.0729 - val_accuracy: 0.8183\n",
      "Epoch 5/5\n",
      "148159/148159 - 194s - loss: 1.0709 - accuracy: 0.8179 - val_loss: 1.0670 - val_accuracy: 0.8183\n",
      "training complete\n",
      "종료시간:  2021-07-10 16:28:16.106839 \n",
      "소요시간:  0:15:53.584477 \n",
      "\n",
      "\n",
      "26145/26145 [==============================] - 11s 435us/sample - loss: 1.0670 - accuracy: 0.8183\n",
      "Accuracy: 81.83 %\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "stime2 = datetime.datetime.now()\n",
    "print(\"training start\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "hist= model.fit(X_train_pad, y_train, batch_size=64, epochs=5, \n",
    "                validation_data=(X_test_pad, y_val), verbose=2)\n",
    "\n",
    "etime2 = datetime.datetime.now()\n",
    "mtime2 = etime2-stime2\n",
    "\n",
    "print(\"training complete\")\n",
    "print(\"종료시간: \",etime2,\"\\n소요시간: \",mtime2,'\\n\\n')\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_val, batch_size=64)\n",
    "print('Accuracy: %.2f' % (accuracy*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\samsung\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: model1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 43576/43576 [1:13:36<00:00,  9.87it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>과제명</th>\n",
       "      <th>요약문_연구내용</th>\n",
       "      <th>data</th>\n",
       "      <th>contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R-FSSW 기술 적용 경량 차체 부품 개발 및 품질 평가를 위한 64채널 C-SC...</td>\n",
       "      <td>○ 1차년도\\n\\n    . 개발 탐촉 시스템의 성능 평가 위한 표준 시편 제작 시...</td>\n",
       "      <td>R-FSSW 기술 적용 경량 차체 부품 개발 및 품질 평가를 위한 64채널 C-SC...</td>\n",
       "      <td>[RFSSW, 기술, 적용, 경량, 차체, 부품, 개발, 및, 품질, 평가, 를, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>다입자계를 묘사하는 편미분방정식에 대한 연구</td>\n",
       "      <td>연구과제1. 무한입자계의 동역학 / 작용소(operator) 방정식에 대한 연구\\n...</td>\n",
       "      <td>다입자계를 묘사하는 편미분방정식에 대한 연구연구과제1. 무한입자계의 동역학 / 작용...</td>\n",
       "      <td>[다, 입자, 계, 를, 묘사, 하는, 편미분방정식, 에, 대한, 연, 구, 연, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>저출생체중아 가족을 위한 지역사회중심의 퇴원후 추후관리프로그램 개발</td>\n",
       "      <td>본 연구는 퇴원 후 저출생체중아의 퇴원 후 추후관리 프로그램 중 가정방문 모델과 가...</td>\n",
       "      <td>저출생체중아 가족을 위한 지역사회중심의 퇴원후 추후관리프로그램 개발본 연구는 퇴원 ...</td>\n",
       "      <td>[저, 출생, 체중, 아, 가족, 을, 위, 한, 지역, 사회, 중심, 의, 퇴원,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>폴리싱용 5축 CNC 정밀 마이크로 시스템 개발</td>\n",
       "      <td>(1) 0.5~1㎛의 가공정밀도(면조도) 구현\\n\\n\\n - 국내에서는 연삭기를 제...</td>\n",
       "      <td>폴리싱용 5축 CNC 정밀 마이크로 시스템 개발(1) 0.5~1㎛의 가공정밀도(면조...</td>\n",
       "      <td>[폴리, 싱용, 5, 축, CNC, 정밀, 마이크로, 시스템, 개발, 1, 051,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>다결정재료의 미세조직구조를 고려한 확률론적 응력부식균열 생성예측모델 개발</td>\n",
       "      <td>총 연구기간은 3년으로, 연차별 연구내용 및 범위는 다음과 같다.\\n\\n  ∙ 1차...</td>\n",
       "      <td>다결정재료의 미세조직구조를 고려한 확률론적 응력부식균열 생성예측모델 개발총 연구기간...</td>\n",
       "      <td>[다, 결정, 재료, 의, 미세, 조, 직구, 조, 를, 고려, 한, 확률론, 적,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43571</th>\n",
       "      <td>포장용 인디케이팅 잉크 제조기술 개발 및 인쇄 공정 기술 개발</td>\n",
       "      <td>■ 포장용 인티케이팅 잉크의 신뢰성 확보 \\n\\n\\n■ 포장용 인티케이팅 잉크의 양...</td>\n",
       "      <td>포장용 인디케이팅 잉크 제조기술 개발 및 인쇄 공정 기술 개발■ 포장용 인티케이팅 ...</td>\n",
       "      <td>[포장, 용, 인, 디케이, 팅, 잉크, 제조, 기술, 개발, 및, 인쇄, 공정, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43572</th>\n",
       "      <td>루시아-신속/정확/저렴한 현장진단용 혁신적 혈액진단 개발</td>\n",
       "      <td>1) 본 연구팀이 보유하고 있는 특허기술인 C-ECL은 전세계에 존재하는 두 개의 ...</td>\n",
       "      <td>루시아-신속/정확/저렴한 현장진단용 혁신적 혈액진단 개발1) 본 연구팀이 보유하고 ...</td>\n",
       "      <td>[루시아, 신, 속, 정확, 저렴한, 현장, 진단, 용, 혁신, 적, 혈액, 진단,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43573</th>\n",
       "      <td>ITER 삼중수소 저장·공급 DU용기 개발 및 시험</td>\n",
       "      <td>ITER SDS DU bed의 개발 제작 및 삼중수소 저장?공급 및 in-bed c...</td>\n",
       "      <td>ITER 삼중수소 저장·공급 DU용기 개발 및 시험ITER SDS DU bed의 개...</td>\n",
       "      <td>[ITER, 삼중수소, 저장, 공급, DU, 용기, 개발, 및, 시험, ITER, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43574</th>\n",
       "      <td>무결정립계 금속 초박막의 제조 및 이를 활용한 기초 연구</td>\n",
       "      <td>본 연구실의 연구는 크게 다음과 세 영역으로 구성되어 있음. \\n금속 초박막 합성 ...</td>\n",
       "      <td>무결정립계 금속 초박막의 제조 및 이를 활용한 기초 연구본 연구실의 연구는 크게 다...</td>\n",
       "      <td>[무결, 정립, 계, 금속, 초, 박막, 의, 제조, 및, 이를, 활용, 한, 기초...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43575</th>\n",
       "      <td>산업용 M30 SUS Bolt의 생산성 향상 제조기술 개발</td>\n",
       "      <td>ㅇ원재료 Loss 절감 공정설계기술 개발\\n\\n\\n- 공정설계시 최적의 체적 조건을...</td>\n",
       "      <td>산업용 M30 SUS Bolt의 생산성 향상 제조기술 개발ㅇ원재료 Loss 절감 공...</td>\n",
       "      <td>[산업, 용, M, 30, SUS, Bolt, 의, 생산, 성, 향상, 제조, 기술...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43576 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     과제명  \\\n",
       "0      R-FSSW 기술 적용 경량 차체 부품 개발 및 품질 평가를 위한 64채널 C-SC...   \n",
       "1                               다입자계를 묘사하는 편미분방정식에 대한 연구   \n",
       "2                  저출생체중아 가족을 위한 지역사회중심의 퇴원후 추후관리프로그램 개발   \n",
       "3                             폴리싱용 5축 CNC 정밀 마이크로 시스템 개발   \n",
       "4               다결정재료의 미세조직구조를 고려한 확률론적 응력부식균열 생성예측모델 개발   \n",
       "...                                                  ...   \n",
       "43571                 포장용 인디케이팅 잉크 제조기술 개발 및 인쇄 공정 기술 개발   \n",
       "43572                    루시아-신속/정확/저렴한 현장진단용 혁신적 혈액진단 개발   \n",
       "43573                       ITER 삼중수소 저장·공급 DU용기 개발 및 시험   \n",
       "43574                    무결정립계 금속 초박막의 제조 및 이를 활용한 기초 연구   \n",
       "43575                   산업용 M30 SUS Bolt의 생산성 향상 제조기술 개발   \n",
       "\n",
       "                                                요약문_연구내용  \\\n",
       "0      ○ 1차년도\\n\\n    . 개발 탐촉 시스템의 성능 평가 위한 표준 시편 제작 시...   \n",
       "1      연구과제1. 무한입자계의 동역학 / 작용소(operator) 방정식에 대한 연구\\n...   \n",
       "2      본 연구는 퇴원 후 저출생체중아의 퇴원 후 추후관리 프로그램 중 가정방문 모델과 가...   \n",
       "3      (1) 0.5~1㎛의 가공정밀도(면조도) 구현\\n\\n\\n - 국내에서는 연삭기를 제...   \n",
       "4      총 연구기간은 3년으로, 연차별 연구내용 및 범위는 다음과 같다.\\n\\n  ∙ 1차...   \n",
       "...                                                  ...   \n",
       "43571  ■ 포장용 인티케이팅 잉크의 신뢰성 확보 \\n\\n\\n■ 포장용 인티케이팅 잉크의 양...   \n",
       "43572  1) 본 연구팀이 보유하고 있는 특허기술인 C-ECL은 전세계에 존재하는 두 개의 ...   \n",
       "43573  ITER SDS DU bed의 개발 제작 및 삼중수소 저장?공급 및 in-bed c...   \n",
       "43574  본 연구실의 연구는 크게 다음과 세 영역으로 구성되어 있음. \\n금속 초박막 합성 ...   \n",
       "43575  ㅇ원재료 Loss 절감 공정설계기술 개발\\n\\n\\n- 공정설계시 최적의 체적 조건을...   \n",
       "\n",
       "                                                    data  \\\n",
       "0      R-FSSW 기술 적용 경량 차체 부품 개발 및 품질 평가를 위한 64채널 C-SC...   \n",
       "1      다입자계를 묘사하는 편미분방정식에 대한 연구연구과제1. 무한입자계의 동역학 / 작용...   \n",
       "2      저출생체중아 가족을 위한 지역사회중심의 퇴원후 추후관리프로그램 개발본 연구는 퇴원 ...   \n",
       "3      폴리싱용 5축 CNC 정밀 마이크로 시스템 개발(1) 0.5~1㎛의 가공정밀도(면조...   \n",
       "4      다결정재료의 미세조직구조를 고려한 확률론적 응력부식균열 생성예측모델 개발총 연구기간...   \n",
       "...                                                  ...   \n",
       "43571  포장용 인디케이팅 잉크 제조기술 개발 및 인쇄 공정 기술 개발■ 포장용 인티케이팅 ...   \n",
       "43572  루시아-신속/정확/저렴한 현장진단용 혁신적 혈액진단 개발1) 본 연구팀이 보유하고 ...   \n",
       "43573  ITER 삼중수소 저장·공급 DU용기 개발 및 시험ITER SDS DU bed의 개...   \n",
       "43574  무결정립계 금속 초박막의 제조 및 이를 활용한 기초 연구본 연구실의 연구는 크게 다...   \n",
       "43575  산업용 M30 SUS Bolt의 생산성 향상 제조기술 개발ㅇ원재료 Loss 절감 공...   \n",
       "\n",
       "                                                contents  \n",
       "0      [RFSSW, 기술, 적용, 경량, 차체, 부품, 개발, 및, 품질, 평가, 를, ...  \n",
       "1      [다, 입자, 계, 를, 묘사, 하는, 편미분방정식, 에, 대한, 연, 구, 연, ...  \n",
       "2      [저, 출생, 체중, 아, 가족, 을, 위, 한, 지역, 사회, 중심, 의, 퇴원,...  \n",
       "3      [폴리, 싱용, 5, 축, CNC, 정밀, 마이크로, 시스템, 개발, 1, 051,...  \n",
       "4      [다, 결정, 재료, 의, 미세, 조, 직구, 조, 를, 고려, 한, 확률론, 적,...  \n",
       "...                                                  ...  \n",
       "43571  [포장, 용, 인, 디케이, 팅, 잉크, 제조, 기술, 개발, 및, 인쇄, 공정, ...  \n",
       "43572  [루시아, 신, 속, 정확, 저렴한, 현장, 진단, 용, 혁신, 적, 혈액, 진단,...  \n",
       "43573  [ITER, 삼중수소, 저장, 공급, DU, 용기, 개발, 및, 시험, ITER, ...  \n",
       "43574  [무결, 정립, 계, 금속, 초, 박막, 의, 제조, 및, 이를, 활용, 한, 기초...  \n",
       "43575  [산업, 용, M, 30, SUS, Bolt, 의, 생산, 성, 향상, 제조, 기술...  \n",
       "\n",
       "[43576 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "test['contents'] = test['data'].apply(lambda x : text_preprocess(x))\n",
    "test['contents'] = test['contents'].progress_apply(lambda x: tokenize(x))\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43571</th>\n",
       "      <td>217875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43572</th>\n",
       "      <td>217876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43573</th>\n",
       "      <td>217877</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43574</th>\n",
       "      <td>217878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43575</th>\n",
       "      <td>217879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43576 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  label\n",
       "0      174304      0\n",
       "1      174305      0\n",
       "2      174306      0\n",
       "3      174307      0\n",
       "4      174308      0\n",
       "...       ...    ...\n",
       "43571  217875      0\n",
       "43572  217876      0\n",
       "43573  217877      0\n",
       "43574  217878      0\n",
       "43575  217879      0\n",
       "\n",
       "[43576 rows x 2 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.predict(test_review_pad)\n",
    "results=tf.argmax(results, axis=1)\n",
    "sample_submission['label']=results\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     43574\n",
       "38        1\n",
       "23        1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------\n",
    "## BERT 모델: 메모리 부족으로 실행불가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = list(zip(train.data, train.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61dd3e58faf4487951fde0f6a8c3a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6017a140e2483281a675a21297fd33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:79] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2642411520 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-684f3acd03f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1531\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1532\u001b[0m         )\n\u001b[0;32m   1533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    999\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1001\u001b[1;33m             \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1002\u001b[0m         )\n\u001b[0;32m   1003\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    587\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                     \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m                 )\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    473\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m             \u001b[0mpast_key_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         )\n\u001b[0;32m    477\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m             \u001b[0moutput_attentions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m         )\n\u001b[0;32m    410\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\samsung\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m         \u001b[1;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[0mattention_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"relative_key\"\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"relative_key_query\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:79] data. DefaultCPUAllocator: not enough memory: you tried to allocate 2642411520 bytes."
     ]
    }
   ],
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "itr = 1\n",
    "p_itr = 500\n",
    "epochs = 1\n",
    "total_loss = 0\n",
    "total_len = 0\n",
    "total_correct = 0\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    for text, label in new_train:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # encoding and zero padding\n",
    "        encoded_list = [tokenizer.encode(t, add_special_tokens=True) for t in text]\n",
    "        padded_list =  [e + [0] * (512-len(e)) for e in encoded_list]\n",
    "        \n",
    "        sample = torch.tensor(padded_list)\n",
    "        labels = torch.tensor(label)\n",
    "        outputs = model(sample, labels=labels)\n",
    "        loss, logits = outputs\n",
    "\n",
    "        pred = torch.argmax(F.softmax(logits), dim=1)\n",
    "        correct = pred.eq(labels)\n",
    "        total_correct += correct.sum().item()\n",
    "        total_len += len(labels)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(itr)\n",
    "        if itr % p_itr == 0:\n",
    "            print('[Epoch {}/{}] Iteration {} -> Train Loss: {:.4f}, Accuracy: {:.3f}'.format(epoch+1, epochs, itr, total_loss/p_itr, total_correct/total_len))\n",
    "            total_loss = 0\n",
    "            total_len = 0\n",
    "            total_correct = 0\n",
    "\n",
    "        itr+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cls_model.predict(test_inputs)\n",
    "results=tf.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['label']=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('bert_baseline.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
